{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Neural Network\n",
    "\n",
    "This code significantly overlaps with the code from Project 5: Image Classification, in another [GitHub folder](https://github.com/dangall/Udacity-Machine-Learning-Nanodegree/blob/master/P5_image_classification/image_classification.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (150, 150, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvVeTJLm1JvgdAK5CpizZkmSTw6tm9+4+7J/fl3nYtbVd\nm5kryXtvs9nsri6ZOjMiXAHYBxwID5GVRXJskmZxzCrLwyUcDhx8R5O1Fnva05725En8z27Anva0\np8dFe6awpz3taUB7prCnPe1pQHumsKc97WlAe6awpz3taUB7prCnPe1pQHumsKc97WlAe6awpz3t\naUB7prCnPe1pQOp/dgMAQAgV3SqtAZB6WRL/92fkX9bA8jMItHZvy20AAAEQDY8BsNYg3QtQct7w\nSHIGoveo4WduP/fPRet3t8l+mxy3W879KD3koo+ewy1KvWoJw4Ym61Zsr4H7crHPkwGUnJ+OI5Ec\n2+bFK5JjD/XyTb+52XH8offaPr7TbzR8Rrw3EWHomLz9mb3RD/rMj4Ip/Nlpm+t28n0sbDJW1/rp\nAW7fhHVG8fEZMrzr/1hmsP2Zu4//2VvzYM95z/Dt1t3Dm1Fg5Nsel35Pf94fxeweBaXvvL5vy9mD\nMbvrjR/eE3vxYU972tOAHgdSsCksGvJG2noO4hHaxgH9SpEgAruLU963ntikOX+GwLFdIoa9B7I+\nVGza6J/NawdQ1JqwxxKFxdr1WVxph9fv6PNdXbgOqHYuVvfBbDs4a/PG4S3C+dsfYzAUEe5ry7bn\n09qx7WN2+7XpfbftS99/173Wr//Yef6c+8XabfQ4mAKAbZ1FRNv78CPX74TFPJjpvhvR+sff8fB1\nZuEn5afoClIdw/bG3Hfxlvv4/fyeA1k9gaKBgaR6FT7Nxufu6r+NJqyfuLXZ61xhFyNcZxA72jJo\nwEcffs/569es9+UuEvcc3zHZ18dzOD1dfHaNP3dsqOLazrwH7VgXzR5Ae/FhT3va04AeEVLYsTo/\nFPUMuGayhA1Y60Nu9sAHBrz9KRrm4VPu5fAAQGJraxz8T1fa7e9oU9SQHNkGyOOuZN99kH/XC1h7\nD9BaV7d64G+T7eHxh/WsxcPWt4fcbZfS024RQbfZb9ZW8/R7WEa/YXvbU9Pr02t9v8Znhq9Pa+el\n48KK9Vt9lB4HU0hlX2viK6Vy8sdkaz5OfI94v1QTvYtZ7KC0LbtPSv76NqeydzJwEjh/P+QTW8+7\nvw33M5LBE7b0pd2ikyBQnAgPHlTrb7bL1DaYBhtHt2/9qXqdh8jXa8/ZMPVtXksUP+2uYWXXGArR\nfc9Ybw+3agfDdYxgc2Fw7UoXr4fRXnzY0572NKDHgRQGK12ybmwo0Dx9dC3cOO0T0FNy0T0qyTVF\nI209uHa1X0buszaE42uXp+jVKwO3LEu72ju05Ni1NS9xBBoslPf0WvoOdgfy2il+2IHIsNn++2SW\nh9DH8d1u2qV03KYA3D4+rd3sSwfxd3TIYJfd3nraRFS0pc+dWOLRq03OeTjKehxMYSBg7dBQ2yHj\n2HoPrH/GP4oVDO6w+9CnwrL7BtT6/m33XtNQJ2LCfaL/9idsaF6GffqgmyVQdsN5JmLp2Ma4//6J\nvw5e7dr//tr72N/9C8gAVm8eTSbSUB/wELrPkWjYB9u/7UDPMNA73MNU0icObmsHQ+ahtBcf9rSn\nPQ3ocSAFWAzt/IMjge5ldnT/+nPv09djGT4SxzA4toFaknex4c+a0nHHveJFn0aJQtQ9aguv31Ca\nJpB/HQXT8LqNdq6/86aOa8futF93iVBm7bxt9KeIB5ua//SOQTTzJ/oneUieNHkArrZqGOkeEXao\n2I3XR/+HKHLExsU3Xz+W4sb0+k+nR8IUdhAR/nQRYNvAG2K0jSfsip3Y2ha78+fQozK9/J42bYzW\n7WxxOOESu8qO7trajx/zmb8PM1MaqDSUg+0AgD6AsW70xzaR4Z67JJNnl1gwhOV2gzHQthMRpyGt\nHbZ2cNUOGvbvNmYU25Tef3OCe5EpEWiwvX+2Wy8+Za3Ziw972tOeBvRIkMIuaP2nogQkCsjULr4t\njHaLJjeBeGSRrI7pyrQljHrXHe9deT/+rnE1W+PlD7GSbHjKrK9CyabdsVLfp3fduv0xlGC3bA9h\n7y64bi1thceb+zb7/P6uThXa9wh86+H2W8fRmo1n53PXHZ7ua1vyy+4SM4iPP1ASXqPHwRQ+NVfC\nugz90MfEG+w+mnQwrU/iZLLsCuMdnJ4+M9UpBHPe5hfbGFJ/TBDVgHb0bepxA5tsrw+wLe3Hujjy\nkC+wCYV3XZcO9p3iEP0xI2Bwh7W2bdv+2HXbKL1+nXGk/9+nR0q/+S4RCztnfFwHbLLv4X30OJjC\np1Jq6toq/6crTdoxfDg5NU7NVBmwPnjXL0oQxH3NTH+k3mgE4AFy9/pamrZ6nSmlQ2fnSr0x7+9h\nGBu0Pqzumzy7UN/2nt9MEnLfhPlYG7YztQEPTPbFpuzEBPFp95gxP6409e+7rc93f+lNRpoi3l3f\nacv7b2/4VtrrFPa0pz0N6C8TKQzWwm3Q66ErzQPkfko3PkGFu0F2Tb4fruf3rUHbbvUwzn+Punv9\n5jsWqiF4/YiIsXHsga0cmP4e/u223X8YnUwbx7bfZjiKtuuI7AbcGKppKJy2HfJ/rC+2r/qb97hH\nnNjW5sG9HkZ/oUwhoXuDe3YNj+TccCzVKTzgsVvvMXzmTlrTB7hx9CmgbffA2M3k7nkvu/3wx/UG\n2wb9mpDhu3WjqdsVhevnbH3XLXq14VmbIp+T3nYznCGL3myXe48dHZXuHTD8h4ge22ibopecN/ng\nPkku0c2W/NG0Fx/2tKc9DYg+jYP9jyFBYg0QJ6vb0FskHL0/0n4IdteJ0vuu3Ts8d6Mt66fct/Lu\nyuybbm/Txm+euV3ReV8z1+67zWtx8yGDAw/NYnA//tp2PFoV0twCD6P4XmlOAvd7V7uGK23I2UDr\nx5Ir0vwYm7Bry9baqan4sCFl2Y0Q6vtp9xj5NNHEUafbB534aMSH1HMsatYtKHTiMLPt0O/gT5P2\nAbu1izc1/Nv69CEyHp+ZmJBSj7h7pfCPK8WHqHZ90O0YOwQamP529cA2cjB2cLON6bft+SkTeDhD\n8G1cewEM+3PrA3cpSLYKG5Q8JzmaqhR2KlwexkiG94/XDPp+8ND1kb1bfNlOf5xOYS8+7GlPexrQ\n40AKabagrdAbWM+z8McB3ITtW79ld6iWtiGQXcpIuyaCpCuRX4fWRIS1e2zNr0lr9/XXbIGlu2Wl\nrTd2q9NAsoj3jlfsWjPo4RHjInT0PZSsgBuL/mZf3o8Nac2xKe63g2ckSkBsrwMyQK20fswipDpL\nm5yIJs4LNn1ObLbdlXmJgKBAXOtkl3V7mxLS4tP9H3bT42AKKZGIgkIy+QdpztLTP3K72CWEqOFP\nRY91uL19sN33HALBplGaCcMZ6DfsYPp9nHbpOjZ2r2Hej4ochPVJRiTdphAQpPi2IrrzJlr1cJWX\n7REnz0BHZTWCq7hBYPgWlrdTK5G/PmWcWxvPvCI5zyJRnSRiJtmEJ9o19Up68+T72eGxjTak1pwB\nv/J9s8bg0uevP3bLu6W/LW1nPA+nVCfxcNqLD3va054G9IiQwiZHs2t/U/A2RJnr+OtPUTsOw4B3\nr+qp2nMNbwz0WJvKxHhwl0IvgcnbdHYbCrNkRSMRW7O20gc0QIAgASkyAIDKchTlCABQFmMUReX2\nKwnpE+JS9CvwGYP9byIRALiBgWFEYLRG17UAgL7r0fcdAED3Lbq+Q9c37phuofmYNT1gNb9wVCin\nf7fTR1AkrW/uEFk2govWb5p+M485dpe02wVEB+N38MjdI462iqjbrklFDBrseQg9DqYwSADygOYP\ngovWklUkf4eyIgZOTQ9zZFmn7bLeLly4S8Nu4WHtFn3BWgt26TQIAiTcJBdSQakcAJDnJYqsAABk\nWQ6pCt5fQGVVPCcvUBYlAGBUjTCq3LGqKpHnblgoIQd6HBiemsYX6E3aw5sGBv5r9n2Pruvddteh\n79zE77oWre5Rt+7Y7WqF5WoJAFgsF1gtF+68eolet/zMDtbwtu1de8IMS6dk8m3vFaUofsf7Eh1s\nLEWePSXxNxsMZ5OsV9aEpsWxuYsNkU0XBYvhkNn9pG13e7hGYS8+7GlPe1qjx4EUNqwPqSooQuFd\n16Zuw+nfoe41sQQQYcAPk2d+pKHJdqLCTBWiu7VJa/BP7NAbJiiIKMB/IWRY9bO8RFlUGFUO8o/G\nY8ymUwDAbDrFxO8vRkEsqKq4XeQF8ixDppz4kKkMSjE6kBKCYj+FXko03z5zkW+3sRbGaN426DWj\ng16j7/12D83bXd9BWwPN96t1j4bFjNWqxtXFFQDg6vISy+XK7W9WWNUOTTRNg66r0fc137uDNQ6F\nGNMD0L5lSL/TQMFs1xFA+gk2UZsdYqM18D5EdtuMHwSnOEyfOgSKqULaf/8EDflnBnBjtw+zXc6I\nnwAVHgdTSClMcuB+/LeL7jFVhVNo+5fbcs3u31G2dK0MtqbklPX2D3UIEQlGeV/KDDnL9GVZoird\n9mQ0xXg8BgDMJlNMJ1NMJp4RzDCdTvi8EUZ8fZEVyHMnIuR5CcVMQCkFKSSkZPFjwHxEEHukEBBi\nU6fgnZ0CUzAWxkQ9gtZuUnZ9j7Z1k71t26Bf6PoOfd+j1+4abTQ67SZ107SoT04BAKumRt24a5ar\nFe6WjgksljWWq7socqxWWK2cyFHXS9SN2993KxjdcJfrID7SWn7ETUk9FSvS/cOt9avC1o7Jus58\n7LacEPcN+TVpczCCP+aZ/AlKhcfHFIBUa/bRU21qIop7k7/pfUW4ZiOBygOeFfV7NPgIu1SksDb5\n8BTeiyAAIijWCWRFhdl8DgA4OT7B0cEBAGA2mmDKsv64GqHy26MJJuMpxuMJ/x6hYP1AWRTIWL+g\nZAYpHSOQUsUJLiQESQhmClKI0DaxgxEIISGk26/yDEKI0AXGGujeMQJrTEAEWuuwv+ujTqHX2qEF\nr2PoO3R8Xtu16FpmEF2LunGTumk71Mxg6qbBqq6xXDGTqFssPIOoV7hd3AEAbm5vsVi6/avlEvXq\nxrW3v4XVDbyOiB5kOvZIY5M97FL/uZU+or7k1hjokHfcYOgKPny2TXKLfkoClYfQXqewpz3taUCP\nEylsobRw5lBXwMfjmbvuECwVQ0emLffzC/2uEvGJqRGgoRVrHdb53UTBWpDnBSajEY5YD/D0+AhP\nTp4AAI6PTjBhBFCVJUqG/6m1oKrGGI0mKEdeRxBFgxQRCCkh2RFJCBVWeiLJK79rDwmRiA8EEjEX\nZUAKUgW9g8wUSCTiBAjRMQlBlLDGQHsRodfQpg/bXdcFFNF3PXoWH9quHYgcDSOFtu3QBKTgEITX\nQ9RdH1FEW2NZOwRxt1zgduGQwt2qxdnlJQDg8uoSi7tz9Cv32/YrkO34nYcjKQK9LUZx8uNxfanf\nAgfC5d5iQpuD2F+dnJIMxrWxFdEqwQbnqzUTRUIPlx8eOVOwa9sR4j009fuaFLf1iPOw23rBVoi4\n7TwERVEycISEkq6LJ6MSJwdORHh6dICTwyMczY8AAPPpHLPJDABQjUrkPPmLokJV8MQvnBkRAIqy\nQlFUUBmLCVkBIfzkF3Gykwj7HbPg/VI6ESLoFERgBEKKoN8gEZWeRAiMw51LA2ibilbhXoIGc8CT\nMU7c6IO5skfHfgpd26JlsaJtGnTBjNnF/W0bRAgAWDUt6tZtN20TmUddY8Xby7rG89NjAMDVconr\nm1tcnX9wvy/fYrlwDKJvl0Fp6fwlhrqiOPcSb0mK43EwTratXumhAcPY1GNss3VSMgfCt0nzcyTP\ntEBkFp8gYuzFhz3taU8Dehz5FITa3gjrnWS20Tbz4OaR7XsT7zx+zoOINjY2fkshkOduBZ/PJnhx\n6tDAyycneHLgtg8mMwf/yy0ooKhQsMWhGo0xKp3FIcsTBWKWQ0oFGX5nEAzthZRBuSikhJAJUpDx\nHCI5UOgOxIfEizEqR9P3JLZAMK0FqIkB6uAr0kWPFbWGnaFMImZ0XXR46toOPSsd+64NaKJlBWTT\nshKyi6LFarnEasVmzOUqoIm6a9H2XoFZo24bLGp33vn1Nd6dnQEAPrx/i+sLhyDa+hpW1/yOGgQ7\nfI/BRoI8B2LFGtZcrw+6Rm7N5+sTALshFgxiTNKfa4J0clqnuwfBhcfHFAbp2+9rWzpM18tpbbs+\ngbvJh7EwaxZsbOc3gzRbiX6DCFJmmIzdRD6ZT/HZ8SEA4PnpEU6OTwA4EaHM2dRYVOxVyObCaoSq\n8gwiMoU8i4xAqix4LcpMQWUFZJaFYySj+ECJfCnCKE72w0cMxvPCEYrWB2eJ8KIIhW0hnTcliShO\nBP2CpIA/RYJDSSDlKcMuNggMQmuLvmNmoQHdsf9D30Gz/0PLokTbez1CE/QQdVNjxRaHul6hZqaw\nWMXttmvR9m0wg9Ztixv2ory6usbbt+8BAK9f/4SLC7e9Wl3B6kUwZ6behhtRmRT/272kWWyZx/xz\nOOHTbbv9x5o1LLWkxNMfyhT24sOe9rSnAT0SpCATJJooTe6liBRSP/Khi8hOC/KGAjEtmh6BxA7G\nSgSVuZV5VpX4/PQQXz5zDjdPjo5xNHMKxfFojKJy8L8sK+QsIpTFCFU5jh6GZQXF8QpKxTgGleXI\nsogUBIsF4AAk7ySktUm2dfATMFoHPw5rbXAW6q2BJRl1UxbwPqVSKShGIEpGT8dcqdCWInftUgGp\nqGD9EJmCUOz/oAQUb6ucwEADEITENcJZLPzqZgEGBNA94I0CRlsY7c7pew2tDXp+515r1A2LCfUK\nNYsFq9USK7+/aVCzuFGvnFjRtAlyYEtG0za4XTjU8OHiEm/fOVHip9c/4sPZa9Sra9dO3XA4v3sD\nCsgRgZyBYX0MDewHG/vt2q5dyGCQNi49lohyqQLdgtD3D0vH9jiYAolPSJuynba7eGDwa7dgsX4H\n3kpFBgIy1tYfHozx+TMnInxxcojPjk5wwJaEqhqjYItBXpQh4rCoRiiDWFAiy0pkyjOCPJr7VBbE\nApIKmmF13ba4W7jBfnV1jcvLS9zc3HJDNXK+pus1liuWtesmvJWQAuD2a0vIRxUkixxN0wVHqjzL\nUZQlvzIh43aNiwKKTZplkQMglHxenuVB/BmNJyhHjhEWRYGyZEZYVSh4Oy8UVC4hFZs7lfvn3jlO\nLKPdPwAwXdzWvWMSmpmE7u3QSuEnf9sEprBqVsFUWTc1mqZB00SLRZuKFnz9qmmw4P1nl5f44afX\n+PHVjwCA9x/eoF6ySVPXII7sJJhEVZOKnJ4STryFaDATotkR8Atmqgtbt875Xan5ITKbrt+LD3va\n057+CHo0SGErfHoAeRD1MYsDrf2ONDSkr8M9Idzv6ajAF6fOl+A/ffECX7x8AQCYjScYlSMUBa+O\nZYUsIIUoMmR5GQKQlMwgVQHpIbdQ8M5UXa+x4CCgi6trvH7PSq/37/Dug4OyZ5eXuFku0bCW3sIG\nhWJVzTGfnoTnlB7ylwVG7AshswzVeBJEm14TMi/aZBnKwiMVCbAjUqYytIxAMqWwrFdhFVIAMhYN\nqqpAVXg3a4uiULx/jMnUiVWjaoyiKDAeebftElXF1pdKoSgFt5OCj5mxBBtCtwlWW7CeEH1noVk5\n2XfRzbrXXRQL+hZLL0p0HbtQM1Jo6qCEbOoVOt7uug4t3+uuXuLq9hZvzy8AAD+8fo0ffvjBfaf3\nb9DWDjVAL5GiAUqQ5qazQmL1StwM1nbFXzZRQq4rJ70jU3LOEDRYdN3DkMKjcV7aAaZ2HhlO+PVz\nNt99MxwlOXer7AcUmcCLI+dd+FefPcHPnrnJdnT6BAcHTodQVhWqahzMi0JkwVQoRB4mvsryIHdD\nKGgQlhzgc3O7wPmFG1RvPrzHj177fXGOyzsnIixXK/Qsw/bGRSn6IUVAcDjSucXRyE3+g/kBjg6c\nmHNwcIDjI7c9GVeoChdpCQBZJpH5uAaSkMwIJcW06EQEw8DSUobeAh03oNcmOCIZrbHyMQmrGrcr\nN3PFokZ+4awCVSGQZYmOoqxCDohRWWE6G3Obp5jPvd4lihtSAFYQuMmQEuglH5MCuuN36aPzWK4z\nlPyMzlp0ukeTWC+8xWK5uEPLTNkFcXWhXaOiwpS9SE/mMzw/cs5QP75+iVevvgMAXFy8Rte6GAt4\nJyiwg9FgiG3XfllgjTNErZdLL+eZzHpqoS0CtEUQU+gTUsvvxYc97WlPA3oU4gPtMvQC2I0h7lcb\nrt9l98MBm/BGKYDZyK1gv3x6iL/5wiGC589f4ODQIYXZ9ACTqVuNVVYgr0awIcFmkvhUSAgR0UHP\nirGL2yXenZ3jp/dOHHj14QPesV/+dV2j8VaC1CvFRohorLPtS263khlGrNz77Mlz/N033/D2U5wy\nOjiYzUIYdpGXkEIkqdZiPgsCQXhHJlJBLBH8PoATK4gEIKLIZbwCTBA0X5OiiVVvcc3I6Pr6Boub\nG/Qc4ixJI+PuK5QMCs3peIrjQxcxenp6iNmMUUOVQeVikId3oIRk64XpLAz3pTExpNvAwsCiZ6zV\n9b0ThwAs7u7QcMRlvVoFp6imbbCqV1hyTofF3QJXtw7FXS/u8P7SWSW+f/UGP776HQDg5upH9O2C\nG+MVkVFOCGv7etanAA62WOKS8RBPX7dM2MGp/qy2/Yu2Pvx5mAJ27N3MpkbIWSh+eVDhr184S8Iv\nPn+Jp8+eAgDmhyeYTt0AHU2mQSywVgCk4oQhBcMPaDuDxcoNqpu7BV6xWPDd23d4c3WJa84V0FoL\nE+IKoipeCDlwuApQXghIqXA6c+385vlL/Jzb+dnpKY7mjmFNJmNUbCHIsmwQNAWDYTEVP/mJIHxu\nB0oTrghIhvtCZc6RiY8ZY4O8n8rOwy9EMDyJWwssOo2b2r3/+c0dzi+crH53dQnDEzSjHtPKtXk+\nm+KARaHJZIzJZITp1DHCalQE3Y/R0aRpTdRDUJK+zcLAWhPEL2M1OtYdNF20StRNYr2oa6zqFRpu\nW71aYckix83dHe6YkVzd3uLNmWP2//777/DDD45BLG7PYXQdnZ9gIWizzzb0CDt+D4ry7tA12CQT\njgXQts1fMlPwtF2nsFtpuOXqXa4G8KskMKskvnnqJtKvP3+CL54/AwCcnj7DeOKUY5PJHDl7JJJU\nwZxnSMJAQvP9Vm2P8wu3arz5cI5XbOd+fXGGS5a1G0uwMgN5f4Asg0iUkJR4FPqVDgYYsd7ii5On\n+ObZS3zzzEVWnh7MMWGlYZHnkLnPqKQgVRIoRcFRAAA5BgTHZCjoEeQg4Yq/RkgZGKGU0RcBAGCj\nGXEgJ+9Y5LSx0CbxMzAaNSs0r+oWFzdudb04v8LtletL3a1QZu4Gs0npmAIrTqezKeYzF3FalWVo\nszHxmZSI9H76iTC2TPCWNNZA8/7OaNR9zOGwXK2w5FwN9WoZ/CGWyyXu2LfhbnGHmzt3zofLK3z/\n42sAwG9//x949+57tI1DF2TaJKtVMsGT8bpZBW0w4xHfKJn8a+7P6UeoH8gU9jqFPe1pTwN65Egh\n0kNDpd25kbYhBQKQs7b66WGJXz0/wn/6zKGDF8+f4+DQwfLJaAYpvYNRAcnaa5BwHoEAGgPcLlt8\nuHR5BV+9e48/vH0HAHh/e4sV5wwwQoJ8qHPhsizLJMTZ82chYpBABsK8ctaPL588wy9ffAYA+Nnp\nUxzN5yjHPu1aFu4lhQw6AZdhycN/GUQckAuOohBEpWLeBKQxDjIgIpUpJBkbORbCbw9XuEFf834R\nHShDrIP3UDQa0IwUem2CTqUxFguOfbhaLHDBuRtvri5B6IPpczoZYcbp6Io8x5gzVE3Gk2AGdg+O\nm4IA5dtGNmaqTnJoGAFoXsVb06NpWiwYKSyWC6wYHSyXCyw5b8NqtcKSA7Jub29xducsET+dn+Pf\nvvs9/uPbf3PHrn8CcYp7golWgvDHtWbTpc7vSI8NxYR4sh0gh6b5CxIfKPFT2HLUnxN3bYlq3OqB\nQMPjnrFUhcBXRw5u/82XJ/j6s+c45SQn08lBMC9mKuYpkFkJzYzgbtXhhj/8h6tr/P7Va7xipeHF\nqkHn+zRxGRYqihxEBGMspIfvJMMrZTLHbOSg8DfPP8Nff/k1AODzp09xwElZxuMxsiIP+RSkkDFw\nKXlxkTAIQIC8X4RUEDILIoCQMsBMspREOSpIf46gAfx20ZR8Z4Go9COAIu9JtmmL3MtAXttQ6sH0\nAIv36HsbPDq1MaFfb5oeby+XIbKxubtGxcb1qiqC5+lkNMLR3OmBppNp8Pr04o5naopidbt0shEh\nFGgy5EQen9hlsVxgsfQiwyKYNFfLJVZe79A0uOPt68UCb6+u8JsfnW/Dv/7zP+MdKyRNex1cpomS\nGleURGXaYSaFtCM3RIYoS6T84cFMYS8+7GlPexrQo3FeStWH6wqWh9Da4pNc7xVowNHYrSC/ejbF\nr146ZPDyxTPM50eYjJ3SqsgKZDI6HGleKhZtj4trB1+/f/Ua33sR4foal8sFOr86qzwoDQUhJojt\n+wBRQRIwgI8DkwIh7drnp8/xN1//AgDw9YsXeMKh1+PpBLmPNcgLqDyPMF+oiAhsdFQhxCzRJEQI\nryYhHXJRHqkgKqQMIL0jkJJBASkk+dAJ914JOkjDokkCiIWoEu2ejWhCkNd1hnb67ycsEALpDSXm\nRQnduwOTLsPxrMJXz9w3e391i7dvHWq4vr4GWXfRslmFkOiD6RzH3noxGiGTMtSt7C2C0lEkQhLF\nV4HilVr5RLhlBcl9JgFk3E+5Ehwb4mInfHzIeDTGaDQKWbefnZzi//lXZzH6w7/8f+jvHNK0aYmD\nYekonhtbBIr0tGTbDhIMP1z8fiRMITG1PMSqQCKBTJatDJsmSgKg+Au/mOf4u6/coPjF5yc4OXKT\nbVROUeZlYARSZgD7FjTa4oy136/efsC3P/0EAPjh3Ttcs8uvhrPbhwhGa6LRHACIt4UMTIEEoZAZ\nRpkbME+wZe+1AAAgAElEQVTnh/jF518CAH71xZc4PWKdxnSGitO651UVmILkJCsUUq1FiwVBBMzr\nTJrRFyFOUAGZy2CGtdbC6mRS8EyQMhrTpYxBS8KLBdLLD0mfE0U7uUYsqpVo/71nXoS2qWkgiiWQ\ngO9WWQLK8MTrLYoWGHfu4Hh0hMOZYxBvP1zj7YdzAMDV4gKKtf2N1liyz8Hx/ADHs3kQJwQl/BoR\nPqtkgknyHp7RdOx1RNIYKIb/ChaZ8P4jEjkz3iLLUCiJSajKNUbBvi7/tZziN//wf7t2Xr8CBf2G\nxXoauO2GeIoWjMQokSZpsTsCsLbRXnzY0572NKBHghSAT4E3wJrjzYAiR8wk4YsDZzH4+68O8Iuv\nHFw7PD5GkTsYJ0XpoDhD685YXF47DfP7y0t8+71DB797+xbnrDTqtAnPJZIYZDPWBF+hiBA2naKT\nV5BRnuGLk+f4nJ2hXj59jmfeSWo2R+WtCmUR8jZIGaG8g+WJQlBEy4JLyMp+Cnk2yFngYwcsuZWf\nFzq3w69I6/Z8v4ISIFIFoqK4pKSrkI3vvL5qBcW+5pwVqSLYtzNVjhHiCFUUtkkBWU5QHoStLBR7\nkZbiELOJ679XNzO8Z2Xk2d0CjVdgWoum73EwZsVtWYQQ8YEkZaKFwgpAiujtqYRCwWIiWQPJrZZE\nUP4conB9JghKEDLuREUCGSMf9dd/C6Occvvf/tv/hfbSKSDJNIlVgTszwq0k63Pqs4Cw7bKKfdq8\nAh4JUxhaFnYYJ3dYSWwQXKM4UfDtvpor/P2Xzvno518+wcGhEx/K0RR57mA5IYOgDCsudnq5uMMb\ndl/9l3//HX567zztltqsZcb1E9QC2gT5FDCwvugM2Ziqi4AJC+U/mx3h58eneMr6gsOTkxAxmOdZ\nkltBBhW5QcxpKIUFjAEJLybZEMQECt7HIOkiDQEgKwkcpxXgf+omHEw1Bs7lEIDtk26l5Hysabx9\nlwBu9vtRZQDy3oXhj3uWEy18+1NRAhgMAH+vzEZdhWeOfF6mCFTyu0FAEEemqkMccrr895dXuGFX\n8veXt6jbDivO/3gwGmM+Ye/IMnpH2t6i7TlFvSBkyk1s1wYJIXNuWhR6BVFwH1dCBL4p4b6L5O8p\nBUH6SlwAJJyVKTcC//yPnOfi4luQXiYdg/idEqZq15z8aLAVx8hDaS8+7GlPexrQo0AKjqJWdYt+\ndfBr6JDkdbJuZyGALw/dkvL3n0/xi895NT46RMFBQy71GYca9xbXyzu8v3ROJq8urvCanVL+8P4c\nba/Dc9Kw1dRqbGFB7HxDQsD6YigkwsoyFxl+MXfBVV+fPsPp8THmHKPg0pvFDMxeFLBJjUcCRV0S\nQ3HrS7XZPgQkkVQwXnyxEsXIfeJsRCAZUcugcxNFISiB6clpTpGdrEaUQllE/B96xSENm4hP8VyP\nOnhN0hbwiCIptQAg7Kc2nm4FowZ/Uw1I/jalAqhiRy4I5Gx9GT99igv28/jw4RyXt1eoW1+2rkfH\n4t/cWoyKgq+PrTbawFgBE8K3KWheQ3sAKAiMWBTN8iyIf6peQbUNpORQchH9JKSI+SgyqJAa71/+\nocfq4vf80itgUJxorb8HElxqmWDU8wmh04+DKdgoo6d0vzyUgiSLgqH0z2YK//lzJzL84usnePLc\nTcS8nMDw63adxopz7a2WPb5/c4Fv3zqT0PvlAjWH9rW9XWtWzGBAIUGGANsBwzkevhdk8JQF958f\nP8PLFy8BAIeHB6jKMiQ2yYsiODYJqWKFJoqJDAmIKnLNrChFlNZ//KS1NklzJobvYk0cSKSSA2QB\n7wSokm9gbHh9EuTtrbFbfNsMxQneJfH/MmExBDeJ/DUiHnL38m1E0E9YrPGdqAZxl/piPBYQfH0u\nCGOvk+k0chYlRkWJs6sxLs+dvuHd5RUazpvQ9B1mvkZnXiDzwWHWiWzQ7ttoJNnBhQqvAoiQw0Fm\nGTJmMNVkhNVqhTs2kao6RoMKoiCyEASE+cKd0/9v+O//5G68uv4O0O0niQGub5I+fyA9CqZgk7+U\nCktJSG96juOM3gQmkAnClwfuVf7zV1N885Uz6Z08PUHBuQPbTmNxx5WJG40Fm+Bend3hN99/wIVP\nrGFs5KqEBB0kzbI+RTq3hlJ2YTHhHy/LMb44ce7Tz54+wXTCGZkyV4JNpmXbgiJgiA6C+601sDza\nDZxy0fCgVFkGNXKDzwoKXojFRHrr6sagoHSGJRGTFgnzSE2NYg0ZrNvJ0+2EX0a9WGRi8KbKlBfJ\ncFpEggnSsImV1y+MgSmkSsvknipxrSYhIbVXBmYoj46CO/S7Dx9wfuOQYt20IcHrbDTGxOfYlMop\nDtncq2wsuEtChOA2WAnN9SWsjpm7CiEhRfRwbasGKw7DVllS0k9Q0EMR/QLaOjPqP//DAovb97Cm\n5X7SSd9uojS/HebPJ3gu73UKe9rTngb0KJDCJiWr8Nb9ca8ig6djiV8+cxz9xdMpMkYHq7ZH0ztL\nwmLR4u6O05+tLM4cw8W3by5wdreADuIaIVEdDExqA1NZ2kZrIVmPMBcSX3EQ08ujYxzOfUhvHuCi\nlLGOIwBYY2I+AmsiV7cmIAVjLSjnVWc6QTmdwLJmvKhyTE85A/NaAZZdgUp8U/eYVQfr7XVCgjjJ\nDApyxV34dXeJc4MkH8ICubcOpF+PgC5CfEK0IrjAAy/+2BAHkiIw3x3+f0uJqJR4R1oaGDnCSp1H\nQw4X+yWQ4iCqogj5Ly/PPqDpnMWpmbZoxw41jIoSuZAo2NybKxXMmFJJKM4SQzI22miX3AW+eZQh\nUx4FIARfDVdxC8uwyNhjaP1zAIBe3uEff/Pf0K7Y89FEG+9uv6QUiv2l6RSQDDhaAy9+JBAQgY2A\nYB3CSQX8+jTD8zlHMFrCzbWDZbTQkKzBaRvg/Y3jBN9ftnh7xcEsdQNtMRAHBtq1VJRJZH2vDFSC\nkMHikNv2RVHhCbuyTsYFity7FjtXYYCVibBRIZkwBasNrPZphGz0RBMUPOjKwxmq6QjgCMK+6aAb\n9qjLkvZLAvlEhhZxFq1BbXu1Amp+ZqZALIdT+ZHhsW0wpmNPJafooU7D6Mg0SCYMZKAwS+6XiALG\n8L9EDxEDsqKuw0oEGZzgxAn3PHJ8iPOYCpFDPnV+IlJInL9/AwA4OztHxxB/PBqhzHJUHClb5QVK\nn5TX5EFfJSS5hLdw5lHLTMHoDlo3aFr3u17VaBsnsjZtE765FEBVuOtPpiPYJ04Ubv/2V7hdNfjd\nt/8VANA318nc+Lho8Akqhb34sKc97WlIjwIpEEUojUFZbYqwxwIBLhFhxi3/2WGGZ7MKOcO6etkH\n85DIRVgN3l01+O6DEyU+3LXBKcUAAIlgBnKl1P2mCPBTpOHJQgTHk9waHPeEp7xqHBY5ytxnUZIR\nsiavZXUP0/UwktvQGVi/LTQsmw6tiggmq0bIGYGoLANZC+JsQZnpoK8dzDVkoThdejbKYb0jkjWh\n/e4dorJUFAVQ8YFRDlS+A7GT0lRf69Yxj0iEEsHhyjaGvT0Bayh6PfLlAShYhHR2FjGISmtn2HB9\n5EzJg1ifECMQEUliNQREjIMx1sK2QOE/uSQQp7V/dnIEySvvuzev8YFzOCwXS4yrMqTMr/ICI1ZC\njqoRyorT3uV5qIolKOau7AxQ1x1ufF7H60usVg6t6r5BmqbNiw9lRjg9cGZ0Y07R/N2vUC85b8eP\nv4XpbrnPkrD2tSzPu5z+7qNHwRQc2bX/wcKnn1UmvHguLJ6O3f7TkUImKFQqNhDBxKYkIHN33uVi\nhSXnRMwEgmHYwHWqRaL9DV5rFGR/V2zVnZNZIGcfgZm2OKUMcz6vUBIqeBpGUcAYDeNTfukeWutE\nfIjeitYQNDOsvjcQnChgfHyA0lsvlIXsV7Cd05HIvgYtnWt2c3MHy4OSZoeQJ84ka4XzZwAAUhI2\nl3Eytx2Qq3BejOHH0IyZJpHVFraPk98zYmujz4hNIyOzWIHatM7VGKzXoaSmgyCC4fv6CEnuTBgv\nbmTOHumfTxiuHSF4SMaITwsLNgo41N1ZSGZM0tgQmZkTYc5p3O3JKd6+cRedXVzgTkmMfVAaENyc\nZ5MZ5gecv3M8QcFRkkQIhW9XzQq3d9e4uXWT+vbuFg2LD1p3gRFlAsjYyiTJhtT7p/MZ/uZnL9H2\nfw8A+D+bFu/euoQtRg+ZSqRoKv8U1rAXH/a0pz0N6HEghS2ZlOKx6L/g7bfTgnA84cpDRQYIguZ7\nFGURsg5b2KBVfzrKcciZgTtrcMuKteta47bRaH1qsCR4wGUX4m0CJD+jbHvMeBU7kBJVJqB8DgKy\noJBvvIPxVZx0H5Kw6l7DGAPDSMEkRneb+EBYSpGKhWQ/+P79FczdNTSngLNtG5COJInW2/bvWoy4\nxqWsCvQfLrkvAVnlsBzvYRctMCnDt7A1v/OoRMi9nlgfbG9hu+grYoUNCk1K/Rz8wwBQjuAUJTOC\nWVr03q2/i5mXdDIUjEFAENpoqNJniiIYxKK6rn+89l/EwC0g1pvskizP2il2gzuGMZD8YKV7+Dix\nkVKhgE6zWuDq4hy3cH2YSxHqb94Ul1hw0Z75wUHIoQCyaHuPFGrUXY2aU7D1EuhZnuksBVGw1wY9\nh9vnZFEwoh2PSqgix//C9Ueva8J/+S+cTfrm90GhOez+FDf8pVkfEosDIYE6acIJcmYlABgXErOx\n+3TjaYGqykMCDiFEGFnG9DDafZSZUqFwq8xVsE+1hnC9anF+66D4+5sWi94kj2etsAYU33dkgAkP\niFJJ5EIGHQNZC/i8jHUDy26tttOwXsRRBrYzMJm3XUWcbhKRSeYZcp6U5u4Gdz85U5l5+xa0uANx\n3TRSCjkHe4lMwHKquK6XMJwZGW0LzQ5apq6RqZhnUowPICy7Vp/domexRJ0eQBxOuf19FLEgAEFO\nZwM4YT043ESPpYGpLXUwyiyyMYUcDn0TiynRWhFVExIdEHrWSXRLA90aaGZqBAv4fJNACEjTOtFV\nIOaMcCnpTfD2I2Mjx+h7SGY2mbUo+LvOx2Pcnp/h+sZ5wk6rEhN2m8+yDIa/RbO8Q7vysr6G5vHT\nWQMjbFg8IDMQiwmCDPqGx0zXofdjTkWdRCYlRnmBpyfspPfrr/DT678CAPzjP5yjN+e+0wfGs13G\n/ftoLz7saU97GtDjQAr3UDBTEzDhMOBpKZAxrOrJKc58YY2u7ULdTiVlSLOV2SSWXVKojUAqw8ms\nwhcnLjjp8q7Dj2dudX17fYeaxQ+hLSrmoZWQyFmZl0mHEgJ3NQaWk3taktCKt4sORjFcVz1MHhWN\nsEDP2UqFyqEKX2MxD/USbVOH8GgaVbAwYUXTXRe0a7bvYRZupRezKbor575LuUTGVgk5nsEul2Fx\nlONREOGobZB51PDmPH6HrAjOUoYkkAFU5vEjbXO1jf41bnstz1k+YRS0MtC1X7XjeZRYn0iKIFYZ\n7VCCDwgDATZETlEaoRKzQGGY2Xjgt2Fj3gEBipmP+h6Sn5EDqFQGy1amcVliMnJiwuF8iiL3bs4a\nhkUG0zcwvUczTiErMm+ZiImrlJTQjGINWQj4or4i+NkQp8/zwVYvnh7hr/7KOTb97g/f4uYD169E\nl/S/jS7jn6BpfHxMwdqtmuRCEuaVGy2HYxUsBKu2h6zbMElJUXipQklkHopbQsYy3GhUImevRysE\ntKFQoWk+EXhy5DTJb8+v8YdXLmjm9maFkkdrqVTIGCwEORVESLLSB5OaQQdkLDI0HSxv2964ZCY+\n9kGJuJ0p5GM32IoqB7STQbuuCRl/tdEgKQO0FKAwQSjPYVnu1MbAsshT367QcZm20WTMArvrJ1Pf\nQij3TNM1QMvC/qqG+ZFFlGdPQSNnEkWrYZoWtowDdptvvW0MzMJXxgbU3Cd0YFzLH0oVhO7anae1\ngfAHRNQPWIkA/3WvYU3CVNO4QJF4ga4zqyDWeJNq9LD0OgmpsiAmkrWBwStrMClzlOREhul4hNHI\nl+GTKFiUIhOTxHfaBLmo1y6Yigx7QeYZFKdmEyMB47+t7sJYEkoMsLwlBD3UfD7Gz792cTWff/0z\n/ObylXvn7uqPMkOmtBcf9rSnPQ3o0SGF1I+eENNhlRkw4pRKZRYzC0tFbnUI2n8J5f0JlEJVeW5e\nwLJaPs8zTL2SqKhgSYbVXYPQ8koxG89wzGXj3r65wO2FUyDB2JByS3q3p7Bo2aAJtjCwDSsasxZi\n5NusUM6nmHFp+9FsHhy4XMl615a+vgF1DinIvg+1GEkYCJgQjeffAXDeyjR1bVbTQ9jcPVQVJbJE\nMWgtQXjfhLaD9u2EBbHTAWkEJyP95gPUSeKKTQam5tqShYzh1omm2Cw17MLnTBOwLNdRQTBtH2pq\n2AZBOeviTbgzBbnVEoAaR11g27pVM9T01XDIBw7yB48xIYJVZJAhXAinEGVHCDImOjwJAcEpqlRW\nBOsPaY1KCoAtC7PJBNXIZ3iSQcwjAoT3spIEy+MyEwIyz5H78Tgeh20SBMPKRW362FZBUVHZd+ht\nTBBrc4Gnzxyi/V//7iu8+eG3AIDzdwvnCAKwWLTpPv4xenRMAYh6BEEWI9YjzEuBcSHCfp/PIC8z\nVJMMWR5fRRmfTddlLQaAaj4JY43aHpK/YpnnyIsqmDEhVTCL1Z3GbOYm2PHhEc4/OM3zu5/eoeNs\nzsIbSGwiyXrzmNawIYw2Zg+RkhzD8MxPxGpLggxMx04tpoNkrXa7uA3OO3pVo5A5isJNeFGNkHFd\nRSslMq4rKVUB4StNZwpEbrDoZgUpY3EYUgqaw8rlqApafWQlBD9D5lmwihCMy//g4XerEbQqWVR5\ny0nmsp4AQE+wLVd+er9Ev2yR870BFdKU6bYP1gOXGRrcf0lAk9sTGYHR0H4iEkJVLJk4xEJQnBgh\n9TmLecYmTIOCxUkpGVLjWWtRZApl5YvajiAzH+AmQlwLWQtr3TU5FchLZhxZhqysUHJ27nI0CsV8\nLAwMMyhtdPzOVqNh/UTbt+itDpWyqZB4wqbL//TLz/Hvv/41AODq4gNMfRHeJc16/lB6HExhR76/\nXAIHI/fjdC4x5yxCeUbBnGOhIXKgmrnOJyFgfXBPRyESjaxBwRMEJGHYu0/AIlcCOSv3ZFFC8EAw\nEJh3jhvfHq4wnflisxOcvXHRaouzS6CNyQzJCoiQhckEPYAQFr6CWVYI5/XI5lLTNqDcPd8YDV+u\nKFMEsBlTkIDlRCBZVqE6OApJQ7SxsNzm8cFhML02TQvDOgltG5CPxYeFFSLCMELMP9lpGBbk5dEM\nxP1iMwlM2VMvcybJlhmJ/rBAwQVeRaEQlk0T9QCmN2GyqqxwylSPzjob9ABKKRiRSLXMa/UylpmT\nxk1hbRMTIzdfGxsQicsxydeoWCXbV4Hy6ExKwDLzdboKRi2Jb3o5KkE6Q8XKWpWrYEmXgkKAniCC\n8m7uaoKMv2tWFMjLEjkrKqXKohmbbIim1LpHx5Co69vwfJCFsAKKFeqqkCB2w/zs5VP87d9+AwD4\n3b99h4vXN9wvXTRJfkLmpb1OYU972tOAHgdSWPO7UsxBnx0LnDi0hflYYsrWh0zGgiVEFl3bgpSD\nz+V4BFsw/F30wWtPtzUkV2GCkpzSDOjaBraqAtfOJEEVvv5jhpHP8TedoOKVOS9KTBg1vC9e4erH\nt0DjHfkRTGckKKRVz3JCwXEMo5FCWRBy4dombY+MOE4/kyh4BTBdHcSPMlchvsPKDDbLgTxCU8Xb\nBgZonUnStrWLMYBDz82V84BUgpzehbXfVlVQXL8yZFp2Nwv9RLkMAU2QAJUiFqjVLSybcQ0IxMFB\nKLMgVclKgpMIQS+M0+8EPQwFb1G3/HJcSmdCajeDGAAl2UIVU41FkQ1CBKuM0TrkzjTGhHOcA2l0\nDLLWJGHZJgl37sMKLklCZmJQFDhk0yYE3UWWKeQ8foqiQOGrehUl8jyHDDU/KXq+wsCygkSnmZes\nhNU+iE1CgkKwnBYCxMWPjw+n+PnnzwEAP/vm57j88IN7r+Y6IKVPqAXzWJjCkHwSy4Mp4dkhJ8G0\nhJw7JM9F0AnIXMJai4a99UbTCbIxmxuVhrlxE0R3XfgIUhZBB9D3Lbq2hR0xzEdEv1kuQV7pRAKZ\nD4ZRGUg4ua2sKszmB3j3m2/dRas2KbxKyAuuEJRLlBx9WFYCZUVeZwWluiBmNHcdNCvglNWhBFk+\nHUME+XSMajKLMqkFutWS25yHwCdBOvhppP4TXathtYUWHFk50hhJNo9lWVC0kVLBU9CCYK9r/kIG\n4rMp8sMR35pg37MXX29guQaD7k0oYksWLjrS3YxNpWxS7RvoM2dSk5MD0OiQ30sEvoHU/Zwc9PdJ\nUW1GQJLsNvoz0FBXkLiPQ8bIL9NZ9L2H7zqY/fq+H+S8kJlKKndHed3AQnrlrMyguPJXXpahqleW\n51BSxahbizBTbeIz4WqI8DOMgA2KUldBnNUVsMKAhBsP8/EIT07dIvVXv/4a3/JYPH+3DBGXe4/G\nPe1pT380PRKkEO1YRMAod9uVBCrW8OY20T5bG73BBEFKgbZ2q97y9g6HXItRjHIY5rq07IJyschG\ngM+ebC26vg1ZcIqqDNmYszyHYEWRJBEKq5BUIbnr9fUCxyenmB6w6fIf/w3tNZsuRcz6bEwD3buV\n1nQrkC4gNDuyWILtGfkIgcKbSeo6xPmrUYmKFaUCEtQbdEv3nPpuFSpcFYezYN6ytothvFpCMtKA\nsmjPbyHZ3liejAGfbSnLINkPn6SEt/1Sb0Cc5dpc3cCOFOwhOzz1Bu2t67+8GoW2WEmQ8F6LOiQ0\nyMYZ2s644AQA7dkHrP75nwAA829+Bsoqbn/MkizzDIKz0FrnLYY886mqyUs5MDZadYQQQ8E0xFQL\nvgf8iUk+h+jUBGuDeVtkGfIih2IYq6FDXIaxNlisLERALSSyUMRXCbfSBxifBAESUfSoFBIkvKJT\nJIWFBHqB0G4jKSikR0WBo7kTbb/6/BRf/tx5Ol6c/wjLSWjTKIiP0eNgConXWUYWPNYwyywy/qxK\nisAUYE3oU8GwykczNncLNCwrT+Zz5DOGuKrzpnAYYZCzfkFAgKxA3bjOy+saWeUHpQ12aqkyCOtz\nLmRgvsMDSOGrv/4VAGB6fIQ3/+Ti3FfnF3GySULLGYO7MoeRIlhGDAzUxEFmJQTw5g/u1u9WqP4P\nlw9BqehLAWPQ3C7h66C1i1Vw4bbjAqJ0k6fXMQeBEATJeQJIK5gVYJdOXyGlhPBWhl6jfv3W9cVn\nT0HgfupicI+5unTBWC+OXdvmY4hTZ6XRjYa+W/mPA8HaepEX6LnOAmUSspAA6zhMfRvqNtjrc/Qj\n17k0PUlS4GEAt0nKaDER0bWBTDKcSATxQWubHLCwicUCQMiybK1F7x0ikHx/ISCVinkVTYzSJNjg\nEal7E/NBaBN1MtJCwMa8lEkKakoZkbYh4Q8hzHv2DI+ikWMYbrvIMsz4254eTfH1N87T8be/PUF9\nds1vkianuJ/24sOe9rSnAT0OpIAY217lwNGEHZYKgTLzsAoxuMUicGyPCr04AWNQLznZ5nSCYsKh\nvwoAe+1pWFfVB87CkMkcYO5eNzXUgpV21Qhq5JVbIsY7QAJjr2SzWNytINkJ4elnzzHhY++/+wOu\n37hV10NeAGjrGs1yGQqF2Na47EdwcRBgRRV9cQwxc7Cwt8GnBqQtLElkHJBkNME0TjS5OzvD5NBd\nY02HLvPBVWNIFoWEHEFmI9Qf3ErdLFbBz0FJCc3Lbnd7A8W++5aE8xYEoNsWkoDMF6e0QD53ZiJ9\nU0Mv2Dfi5g7tGStknz6BYASGVkPmQLe64/7sMPnyc773NYRwzzRSQFIUEULGa7IgGeNfXHZob2WJ\n8QIkKKymJJLiOeA12oscQITvUkBoHwchoTL3LfumAQmENqSZtACE+pG669CxKNsJQu+9awkAZVFR\nKeN6TLDBEmONCaiXbBQ3hF0rA5PECCklMGKF5nw6xovnDmmdPn+CH6+cJQLdPTlL1uhRMIWYDA2Y\njgmHM45GzAVKThcuMkKnvQcaknTp7l+spULofbWfVY0ZJ3OU4wKUu1kltPHiLCQsVJ4F2d20PZZ3\njinIaomKdQVCiMCUBAlkLBaMyhK2dyXFACBXEuLAmUezX/4sRHPenp3BMlNpux7LxQrEmYELUcFy\nNKVWhJwZWTU5iPkKDUIkqJQlyuM5TO2dn3oUrC9YXJ2j4RwKUligTIKzeEB2bYusGiN/4TIYK6Wi\nlQAG1ZFrv9OJuE3Td2h/dA5b2WQE9eQAhp2x6rPL4Hwk+h7EWaaVABpfmu2uBvFkE6aD6G5Bgp2p\nxgTJMmNz1qLkqtG6ytB6/YZJUjZL6SZo9L0aFMsNhW4o2RYIYrX1P/08MVH+MCRCYRaVZWHbamfJ\nCc5wLIL4j+MNK30DtCzbKmvQMVPIBTlLQmAGSYWppH4AJbqOgVjBflRpQm5fAVsKgYLH73hc4ekT\nN2a//voF3n7nFohW78WHPe1pT38kPQqkAEQGOiqBEKYvTXBSyksRNNldp5H5ACgJF0CUhpj6cOG7\nJZqpFyWKANcVKRiftcc4UcKvtL1QMLVb3ZbXtxhP3aqpDvOBm2x02ZUoyhxdG2MfSi8WaIPnX33l\n2qkyLFjRKC1QrxoAd/zMPMD3qizQae9aa9CzyCNttMtLGHSLW+javUM1m8FwfQIiGSwjAgLEBVj6\nZonuzimd8qNTmLJAzn740BrElgjbrNByjUU1mSCbunNIETIOKddWQwiD5t179z1ubiHZd79ftQE1\n5EUFlXs7vQyrrDx7Bfr2/4VhB7Cm1TCcqVp8+XNoFnNUKYNcWN8uAxwQWQEhbShUozVCrgljktXU\nRpETOmogXXLeBGkICq7tkqJTkVQ6IBAhFRQMQqFKLWGEf74NY84gFvvVgmBbhlO5Avro94G12p6D\nfIP38GcAACAASURBVAEJGoinWA6v9nEhInqTG4mcEelkVOCExcevP3+Gfz10aPBtc4eH0uNgCjZ6\nMU7yKB/21qLjwVYKGbwDCQhprYRk62LoPROcZLqmxfLWTYSiqFBUDparogjQnfre5UJk02dBMuZr\nbFrcveMJYik4RZFSIQBICoKSAoYHS9f2kOx8NB6P0LLI8OLrL/Hj774DACyvb5ALBQt2Hrq9Q87p\nwpGp4JSk2x4dZwMmISF88MTdNZY/vIWZu0maF3kwycosD1549cUVxIpFjMuFG5QARv/7BPrKhNAH\nUeQw7JFp31+EXI6yLAD24zdao+OM0WJcoX7zAQ0zubxpQ4UsJQXIpzhfLUJm6npRhwCm6v3vgO9/\nhD1295OnL0DsPCWnYzRnztQqaBQ8Us1qFTw4lSxAwkL7BCYkkopbFpoZtLV2YGoM1gpLIJvI9ESh\nlqUgCdH7XBkyCbgUEDZGkCJTMNZ9p66LSXaUiIVjpUtB7R6pjct54S0WEonMgzh+XVBGbFeaDyJh\nGCK1RFgbvuUoV5jxqvr8dIZnz58AAD58eIeH0l582NOe9jSgR4EU3Mofo8wM86q8EpgesrNIF2PJ\nBSFEpSlJIGGDYxFAsNrjKovVwindqvIGJWv1RUlQHGotcsWIkKGtypDx6qhbjYbTmd0YixHD53w0\nClWGCcIhQa+EhA15DoqyBLFYkuc5PvvyCwDA9//xO+dn4KHgYoW2cu1cArDaQXYhRyH9FhkDzQlZ\n9aKFgIWyXnHao2WLS1mVAan0TQ9z7tpvmx720lkC6n/NIb/6DMYjHykhuP39sgka/+5mhcLnWeg6\nrBiNlNMKNs9iperbFvWZS93WXy1DGHT+7Bj0wtnMUVbQ7GbdVxPIwydYsj+DFGfIvMvx778NYpEh\nDeORztklxNMv3b10BdNKdF38Zt4xihIFnklSQ6ep3dYdeYREELlMqqgEYhi8M3+FfiLKgjWAiIIz\nkkQsFCRCiLZDWrrrIH07ZXTbhhCxSYP9MaZDWOF2h5L10c3aKepZZJMCIxYzD2cVnnPOjt/8doqH\n0qNgCqDgOAdDhI6rOvUdoZxwLsbWorlL8t3BB0cBIAvlO1tIeAdx04sgitTLBZrCwdVROQrhrZnK\nnK6i9/YpHeLkTaFgOLPx6vY25NsrJhPkPKFEXri07L1P5Z6Yl/oeOU9qDYMxB1R99sUX+OE/vkPL\nmnkhW3RL95wyK2Er9/7tqsXywok/SklYn7sxK4B5hZ6ZRHN+HsQpIhtguigLCPZ0IykBwwx21UBK\nAekDl6yBYectW7fIfvmVe//WQF8tuf0Wk88/c22ZjdA1NQTrBER5Aj13MFXVS9gr12Y8OQrdqm+v\nMX7qHLHE5CuYk6cwf/jePef730CzF6j+8RXUE+cUZfIMlpmyfP8ONHOmNruao20pln9PU5mTDYVp\nCCIyLhFzN1oAdg0je9Mf2cgIrI0mTSEloE3wsBQkQnCTkTqEdbskO+k26xr6HqYnmM7rNUQwgyJD\nZASJJsExON4rCIJkxPaSghnUJOqJXEmMOU3cwWyCly8dU5jO53goPQqmkDBAAEDDcujNHbC4ZTm0\npCArCytC37jcGZGDSxlNh5QEmmjdo2NXZtvVyDgNUp4rKJGFpKR93YVVX+YSOpgqNZoVuykbwLB7\npBr1gMpjgVhjo06j7ZBPWHcBgk+oMJvO8Pyzl3j76jW3WcL6lUaJkIXIig7LC7e6q0yCJg5B2DFh\ncnIM6d2eLYX6EtQbaG4nVVXwejR1GyZOcTQHFXl09bUIJkmTC2RjH+Xo+gNw0Y8leyfCWPTLFpZn\nX3ZyiOqpYwp2tUTHiKSvayhWuuZVCTnyRYBL1KsR6CtO4HJwiu7c+XMI0yFjj9T+7g6W/S/0xRXE\nhx/dex08A8k8FqU1BsYkk82rF4hCAFLqvegm+9q+pIydl/VtOkGlgtG9y9gEv9sHe8kQjWmtCfkW\njdFhITGCoAVCrghBMdkuURYYGUy0O9pEiUBwXqnW55KUFK8RhYuOBZDZuPjMZhM8f+6YwsuXx3go\n7XUKe9rTngb0KJCCQCz00nUWXKAIOVlcvHcr1eGhCCIDyEavNQnnX+4LaJAJKxiRDcFBMBqag0Ns\n14QXz6R0MfK8vNheh1Vb5BnIX44uiBhG6+AghVqCCsCzbUEUHF66vofmFTzPCviChT0Rjk6OQ7j3\n4m4BzVmYlne3UGwZEeTCcgFAVSUUw0JRZBBFBsmrcFaU6G59AZhlCOKiUsNKRkdWA6dutZCfv4Qp\nSwivU6hb9CsH+ZumBhjK27wAsSNRPqnQcTo6yqRLO8bPubk8R8Xp4Ej3gI+jEAaaPSIFBPreh2Hn\n0BCwPr/F05dQz52+Rdg+OGmJmwsIcl6XbX4Gy3oT27dAVoa8A9YYZLnPLB0U/CBLQVuf1i32VolQ\nsDZKXDDGJk5FIqTeV5mC6WVEoTIZj4KgvR6jbYPIoLVGz/qljlUFPuRfCBF0LyBCSMBpooUizUhG\n5JCCt+zILOazkFAhi5YRhDGj1ul0ioO50yV8wWLEQ+hRMAVJsToZQOh58snSulRdANqakHFFpSxX\nztgPB7Fs4rOaWHRgBSCMFyVsUHTpug4dL4yFECaYdySlciSBCpbDbXSNdtWoI4x0ooMfcRSKmkIR\napb7JckAyzKVgUjgyTNnQ37z6hU6Zli6Gsc4fWtCfQo1HkEyU7AgdMsV9JIVdzJDywo5ay0K4fUw\nXRh4dlRAzZyitLeAqTv0N2xitEB/5ba7uxoFDzaqSkguaquNRnfnzlG5cu8vvbmyw+K9g/+kO0jm\npNLEAru11pD8LauTsROZfFHVWQbT8arQavQLx3zEeAIxd4FiWTmH9nkidA8DE+G/iIuEKADN8VjW\nxiAoa4ZzzSDqFRLeAZ9yE3AT1+t9VFY4ZxodJ7LXPUiR5EJMCgebJGiqFwShCYJ1CkLEStHC6uCo\nQ0gampa2I+FMpD66VyoIr1wX1rnHA7CS0PEbTGZTjFnkPH1ygIfSXnzY0572NKBHgRQoJsFBRki8\nFQlF4ZUxURmZZXE1ttYMnDpgEZVLgmJadBgYz7XbGpadgtD17lofit2bqL0X0SlGZ5RorEWwXsg8\nhxUS2sdlaAPLfuZKKLTsfNU2NfLMpw5XLoUXB7E8f/4Cb98655K+M2jZkSjP8hDGW59bCL9q5QXa\nTKPj+pfWClRcCFUphZYVjd3VLZRP/ApCx8FJ+eEh1PEclp+je43Wp1ifzQFfir03qN86U6MoZFgB\nF9/+AXQyR++RS9uju3Sre7daYFz5vAcKkp2yquMjGA6gErMS8rYL3qrFkwnaK85a3TZQnKHKmDJY\nL+jkGPr1H9yP5hYYTYMZUAgF6WNkcqC/9cl6o3kyTQlvfKhBCEMg+AFkYGI+Chj0PGa6toW1NmRl\nEokSk5J4CWIrhXu+CajTcqYmjxx02wXlpNQyxlgQBfHVJgV7XMZv6bJog7N/MTqAQhA/rAjR2phO\nGxweOqvDfM7xLA+gR8EUgGgSkgSM2SSXFzZ4MUqZ5jsUyDjNWd/xF05LgIVipzbJe69heYJ2bQPd\nsqzdj2FNEv3W9iDfq4qCzV9mEtZ/BAgoH3GYF4CQIcW4XbUxb4CwwTVb913IkqyUg98dn1eNxzhg\nmPz+wyXynHM7ZHkYeNIYNL7w6dExhDKBMXadDr4RZKLNmsiiZ7GEIJCP5+G9skKgX3E25rpH60UW\nJaFfu8Cn4mgOwbL6zas3Ae631zew3QrZc2diXJyfw7B343Q2Q85WEUtZEAXtu3NkPDAX788AY6Ge\nOjnXdFXQCeWFRDZ1fdHe3KFnk2xZSpg7zlJsBcz4CSzraGyqRzA25JCwGjGXp6DE2uDFM/er73Vo\nZ9916Dtfrar//9t7syZJkiNN7FMzd48jj6rqAxjMyHKWfOJw92X5D/jG/03hrggpMrJCcrmzHAxm\nAHSjz+qqzIwIP+xQPpiamnlkRGZUdQFIjLiKVKVHhN/upqbHp5/qvvp+gG0sosSSouPEcA3JBJSc\nqGYoUg+J3Cm7ASo3w3un72PwhfvRVLz0nB5i+p5SStIIhsSYttQG2FIgCEMaK7nxIz77TFoUfL64\nD4sssshHyouwFCzqklCG9O3EF79swFUdeMWSpWgNYw3YByU+TRZBjjTa4lUwaf55ciOGQ5olt5ub\nNJtkVqXIBa/uXOpjgJTHJ2XitQXf31hQ08KK+RYDK4YBDC2ciijc/tS0MK1R1ujoI66lRPt+38PJ\nrN8PE9br3HjUwkkkP8QJfqLSB4EMvCA3m6vrUihUdzFlIF4LYOtmBe8GsJQ493cHWBK0Z7NSPAWu\nN9piHY0FP0hg8naLcfeA+O03AIB1a2E/k7qSbgtPpbEOiysT7h7g3yZXhPf7VIo+SIl3C7AAq3zv\n4AWwNB16vZfun34N/0+pC5L9u/+AWalQZIzSicqsLEzusBWN9oZAwIw+jYkSGxMA77wyZXvvSnDQ\nO33pJjehQQOXMSDRw8k70DWmNP+tGaRNhaI0JGxRgpuJUft/GiJ1bW1jSx2HMTOWaqIK8EQGVcFG\n6TBmDdZSh3PlNngt4LVf/eoNLpUXoRQam/4B6YGNUzb/SDs37fcjrrKvuQnwU4ZFNwAYFfmd+poM\nlMIXjsiBgxg9RqkqDH6UyK7ECBqLbAtyLKnO1EJMoM3GgsStgDXy8HLbt0Zr6En/AyiigFoQseo2\nWImSGg6DVtndvL7FXc4EuKmiEChVhv3DA2gTFA7cGAsfMgdAhyDnYq43INGwBIBFwdntCtP+AV5e\n8KHfo5WO2OvGAJz9+wGdKKVm08FL31lzuwEbj6C8lpvygl7doP1VIkwxkTH8YyoCC0Ov3IPdL1/D\nrFYa+5h+9zUod7W6uip+fAg6CCYfgC//Jj2X9Q1ArLTwHAOiT+s1g9GoPLuI6HN6sO46TQgcVUk4\n5+ElxuS9R8iNWbzTZTc5hOA0S+SHHrnt3MoarARduWqtFvclfkYtswSMrWqgvCq8GKM2EAIVRKU5\ngmZTXTfJKMsV/yShQSMNhjfrDa6F2ObLzy5HNC7uwyKLLDKTF2EpWAJWot27hjT6f/eTQ9NJcHCM\nivV+ZaGFJcF5KXaR2Z2j8jgRlx6BlceBhIWQvH6YQO1aS2S7rlNshOsHpdwyBgUgY1sQZSCOBSrW\n3di1cJnx1/lyUANVwT56GO/U5PMxwMus125WMEIHN4WgJn7TRWUGNgB8f1DeBx8ium0KJK2vrzGK\nK0Gt0aIgZgByzSs/gboG/kHa0CHC71O59H7q0baS5159oZDnuGowCU5jeH8H27Q43EuJc2PRXd3K\ncqsksP79vbZw67YdnAR37We36H7xJUjK0u0Y4KV/JjlClPPncUIQmLYHg/4mkePyzWsgMoIE/WxV\nEDT2jLWwbU3TqOtwTTxEhBAigoKMSrNeP00KWHLBaVbGBYcQJm0UM459shYA7LxXbMer6y1uhKfC\ntG1pcW8sbNPoLMzMYLGc2Hlw5rMAKraoqvbBmprfeP5CV9kTIoJBbq+4xlYaKd/eXh5ofBFKwQAa\nvbUErHLGwQAhR4U90IvLMDpgKw8+hgmoBn/yB+vhb1E+ZOCI1cEy9Xusug1IbkXbNUqhxs6p38cx\n6ANuqvgCw6amJbnDFFttduunCdoEyFh9cZlZQE05M+GVAIZsQCeAoWHwhc+ACJO8uOMozUtyx6gA\nsEmKpL97q27GtHfKwWBWq3JfbOqAHH9MWQb37i1oyrUcV3DbNKgP332D3VeC3d+PcPs0CB7e36O/\nv1MzeXv7CuNBshz7bws6z/nSZMUP6K6SKdvc3sIfRq1MDBZaeDb+/kfc/fp36V7+1Zfof0ygqPbf\n/C28pDd59CAeABnwpm1h5Zk5Z9Btkh99/apB/5COv9vvKwWZ3hYfKqWQG/mOI3ws7sskxximEc4N\nWl3r/KSuRBwnSOQFFoxO7vlmtSmUabaBNa02omVTGt2EGBGyK+FdAd8RaazCCrdCrTCKxqgqosjo\nO2/sSpsQb8Q9u0QW92GRRRaZycuwFAhqvofIuVUCupXRwEy3iuiEhHS3L914W5N67MVMatpCo/Jk\nWGnGklYVUAlFDRKFaYDre5A0jYmtQ9PmoF2js0mcHGhbosVG88INYjQa54wGBdOOqKYoU6Mtv0yM\nILKam266FjspneamxfqNmHqTRyOzTnCTBt3iagVDE7zUTnCIwJQthR+107ObPDbSoKLprhAEFzH0\nO9ieMT48yFlGbK8l5UOM8V3KErh+QC/nBZaAIgDqGtibK1wL7sAFgO+FDg4W4z/LTL/ZKBEpQZiI\nAIw//pR6NoqlE6cBkGzQ+//tP+Mg2YeV8WBhiY6GEHPbOwfQOCqFmmka7eVoWqv9N9vNGuOYSXwP\n8K70aUjZILFCY4QTi8B7V5ZDUOusPxwwuUEJe31w8FJubiIrbgUMfeajc9jkDuREMNYWglxrZsC6\n7D6G4NVSMRy1B4QUTmjWC7aMDabK5QDUfTamgbWFIuBSeRFKgarahRCBXvDhN5l/EQAFg1X26cG4\nfyeEH12Dq02bmIsBRMO5+ZPUQRRQU2FDZg2WO+cQ3IggffmmwyG1owJAMapVFp0rlGW2VVSMMZx8\nHg0eh3LMKg3pY1REoCGbSDJya/pupdsMbgQrB0OBWtrOYpTjx4cH0KFHF3K5LCFIifF4917bnWNy\n8JL247cThh9TcVG3WmP15kbPx3mPO9neOw+Y3C1qjykDfALjXgYrbIvtzVVBG9oWTvpStqtGuyit\nbjYa8Z8OE3rxwV2cMPkJ688lTTZ49P/5v6ZrWxus/+fUVj3e3GDKT2CYYFtRCoeUIci0+rZrYXLT\nncZqfCC8f1ClDpSUJGLqF5nRhi54BZKN46AUeNM4YsrL04h+2KPXB02aTVq3a+XlXK1adWWnacQ4\nCE/GqkXTNtpQCNZoXMqgg5HJK4yl+2WsC3nISMeuzBtSanSAklmpXYwU78o9Ni8f6i9CKdQSInDo\n0wXudhE310URZLLV9dqi2coM6iOcj7BWBpwNiiJM7bjKzcqKwzYEmwk6jJVadLEIQoCXAUJsCv4h\nEoK8INwmaDOQoLymsVUH46BpTDKYxTqyT9vYBsSAl+tpKpxFGEY42fcUovZq6FYdOgn6bbs1HqZv\n0OcCJQa6QUhn9juspcrSHwY0b9/JZVp4oYSfrrYY/Ygos6jf9wrfjZFBNjfibRJuAclSebhLCmZ1\ndYuIHldyPd2bjQ7QyAHttVRJNhGTHHNwkwYaV9s1VtdrrG7T9fQ//ag5af4ffokh95NAqzwJYXCw\nNqdqE42/EUVkfVcphQZOAqqRWb9/86sv8V6U4uFhB++9DurAxVIY+wGTPH9XDeppHDAMB91307Wl\ncO7qFTikOEbTrBXb4KYJB7GAuiZBoTNOoakGKYsVkHZG+p6EGGViEA5TMoUC3lAdOjspBILJCt7Y\np1euZIkpLLLIIjN5EZZCmaeTf5TN0t2OYcT8vtpC4wYcDToBMnFD8GNAzP3rQcjEW4ZMqqlHKk5p\nZPuusaVZLAEwUDZnGCiizXDp1gOOpSMQF1eAgwfZRqPMYFa2HQ5Rl70vjU8jM1rbIMis40NUdySG\nkKMgGPoBW5k1OTqMkiq9/at/i7/68hf4zX/6jwBShyefLZJ9n+rrAWw21zCSi2MXSuehyQE//AAn\nHInGx9JI9/pK/dbGELz48aOflDnJwSOMEwhpFu02HRrJDJCJGIYUq/APP4E5U5tB6/8DGIf+APo6\nMU+53QP4f0zpxofRYXhIbkpDXtF9wzDAZLr77S0iR3hBu5IbQWIR3H75OaK4nId39zrrxuCwf0iz\n9nDYgyNrb8ya92Aa59bBJBmGaRgwHPaY5H7YroERa7Mhi3G8kme5VpeXY4QYStgfDKgx2Jpi8usr\nE6PyZjCV9xwclSU7xjhjp6bKUNCyiyeEnjMrKnkRSsFHQCxpQTdKGmYCbI4DGCo896EMSokc6EC2\n1mpMwVpoFyCDYqFZCxgNOgYArIFDY4yiC5kZlkqhSnZFYvC6PTgkYoxchIWIkHsguBK0ci5UBTge\nwXb6gKd+r12LJxh4GTzDeMD2NvndMXo8vEuD5WH/f+PVzQ0cckxgQpCdN12r3apgCp4DZLS4hxDh\nDwOmnUCjfcRWqum67RqjnHP/cK9uEtpW8/rTNKFBRCsKd3cHGFFekRldJlmJ0BZqfnR4/de/AgCs\n37yCe/sj7v7r/5dO83/6O+BV4pbAuwc0EihtWouYuyYbg1EKuCwMgjE6kCgAmCSIOQ1KRvPFf/8r\n/OEfE4Xb7p9/KtWHzBJQzIHLCSHkZzZhlABiKo4Sl2sY4IaxCu5FVRB902B3SEqhWXdYS/WrsVYD\niEyJIEXdVqqeDcfivqGQvxCzXmNgho1cuCRr4gcuOAWu2kjFUIiF4iQB4wtkcR8WWWSRmbwISyGE\nBE4CANcAAukHgdGJNj2MpHU6jQfMmGd6IEbSyLJtUFKK1ipTjo0VIxKiBgPB0uA7a2eS34F5vz5L\nqtmZC+cCAHD0JRJMQe065yatsfCB1FIIkTFg1LJsMGmUfAwTRpn1+v0BdzbxLKxXVgld42FCtAFO\nADdj9HiQ/pFt12F9LUEv69Hm9BQMfHZ5YopWZ1Jab3wKkAIIhx12mVnZOdi1sFZfbUGZbr4luMOA\nt9Lm/K83/50GVPt+BDgd34LgBfDkJ4+9kND2b39A/MN3aIUIltbXGvTjrkGQ47hpgsss08zK3hw4\nAC1hJWi93Xdvi3HsCM5LoNC9wShIyf7dDyX701gM/QGT7DvE4j6E4DWl6INXUJEfJ7hhgM+zMAFG\n6PvbzUbdjMNQXLmmbdFKADwSwbQtKL/EhtBJ4RiBlQOBiYorSaTHs0i1HrnYigJD/UyqaiJiREbM\n+WnAKIHOYfeAS+VFKAVwIaYlQE3hKQAH8aONMYj3VUFLjny3yQwjW5yt2hUwuXosamsAyf9Kqs+a\nhDKrqyx1maHci9ZU+y1EGEmBBEXnEbHCoWGAMdOscalqCzE1uDW5QKjbFORi7+Ek+j3cvcP9d4Lo\nayw6SXvZrsW+65TBetofMAjmAAysxMw2TZc6agPYbK8UdWmMTbBsKZCidYuYyWQ4wLyRHgExZXYA\nwBCDJD5xtd4g9FGv7cfvv8Pn/+av03HeXGuxGLuoqVJiwkHa0RmeMH39Fbb/LsURaHcAr2SwuQCX\no/fjiPU2KZhxnGAlbhCJEMhjvRY4cxhTdSsSg/K2TcriN//p77ET8pcwDuoiAIkmLRdBMbGa+RFc\nlCdYXSYfE34gv3cBhSqNqHBpuuDVZO9Ie6MjTgQ+lImBEXEVk8JtrdH3L8SoXgERVAmYEFJ8TZm+\nqWTZYp2JCIiZF7I/oL9PGZd7ufeXyOI+LLLIIjN5EZaCj8rDiq0pffnAjEkshR0H7ZcXInB7JQCn\na4PtijSbwKYw6sSI0rmJbOncg6A8B8bkmV9M81Bq6AGUBqNVcUpVqZrYnSrwFZkUmQaAbrvSPLmb\n4gzTHhG0nh/BKVvPNA04SPR96g96Ln4KpQDIWoSuFNsgBDRCgebHCQG5aY5RROL7H77X3qimbdFe\nXaHLbsZmXYq9WoNWAoXGGLRyM/d39xrYalcW1AD2Klku73/8HjGk49x89jliLijb9/CCbWBD2LxO\nFsiXf/sr3O/3+Okf/xsApAyLNJOJTaP9JwMYD3vpN9m1WAmz9Puf3uHw/ifc3giu/3qF737/dbrn\nqwa3nTA8/fgDDmIpRO+0mCnEZA2GWKwDznRo1io2gEHaRDZyfm45Axa1l+U0Throdt6XrAABed6N\nAGIf9dp8cBrQvN6std6m5OGQ7reRZ2nHlBmT97QNDawTy9XWBYEeXtyn/e497sRC+OG7b3CpvAil\nEFBc/DYCXW4eSwW+TFyCreMUsVcoJ2O9NVpogshKWBFgKsILgPOoiFGBTImQg5VMhGJU1FnTdGqy\nkqVSC08VfwNxKkDKI96SdphabVbYSHHTdN8jckaapSi9RpzHoSD/hr02xZ3GAa2gE4kMVrlJineY\nhkHpwq01ChNvN50CgWL0YMo1+5OCpdAz+vs75XVcff4GISNCW9JmuSCo+7V5vdVCH0OEaFZgASO5\nH0Z8+w//mHb9xVtcv077HX+6hxG36OrLL5VN+w+/+TWoYfQ/pYKs+Pf/J+zf/fu0/OozhenGEOFy\nsGkkBPHPD+9+wv7rb/D/fp0UwasvPkMUboe7hyEpUwD3P3wPJxmWZJ6XitmAQtsWAe36ja646jHn\nq2X9wFG38TFoHGW/32MtlZ1oGzS80vuXuREaQbcqV4QfFTnppwlXEl/p2qZAw2NpLBNigPMOzZg5\nGq3GyBJSV5SNHzAMSZE+PLzH998kZfD2+8V9WGSRRT5SXoalwCmoCCSGnFyX0Bqgy4S1DSnOACaB\nZADAj4z9HaETjdxShJ3BjAvZqmIbuGQbUnaBlYE5clQWJrKkBSyJEDNjJqDqlMGpVVihBtZMBFmj\nHAhkrXIj+BjhQ6xYe532hzjsdgiZW4CgxKvBRUThFrAGiD4oO7GLUa3ObrNFe50rr0zqUwhg/dlN\naW0XIqKbMHkBL42dvgl2ZZQhiQG1lFrqNBJuYAAKylQ9+AFuTLPzDV5hHPdynSOMBMYmP4AzlPiw\nh/MOwzpdwN1/+Qe0Ykrjb/8WJrfDaxolZJ3GEaZJzWrv//AHDL/7g/aB2H31Na6+/ExuQIP3QiLr\nhr4Q9MaoVXdMlCjZ8iNrGiWBpSY/4ESTl0uqEwMTK0w5WXuSMRp67CSg167qwqM5rIitLdZh8BVg\nasA4pmu+2W7QZabwxgAhg88mYKRiRRho4BfRwzsBWY17DQDv9nv8JBmfDNy6RF6GUgAwyMP3VYOc\nWKw3WAaE7R2r1kBY2tJNmhiH94J3Hz34VXoYV1crTU9GLm4Fx6D+JUcPDl5JUmC7WafhoC8Bkbln\n0QAAIABJREFUw2qsobgPMQYwxcINAAs/icJyXv1WBuug8jEk8zNHtqcJ+33KHkxDDyeIOoZFLyk9\nEw3QZMIQj8Ya7UuCEAqvZIjKy9huN9pMhgEFUpFJRVg5jmMMI4b8Ulk4b/U+5eYjTdcqkIu9R+xH\njD+kuorh/k4V8d3332IjFZfGIzO7Ybe/x+r2Ws93//CA98IajemA9fu0L1q1MFKNGQ1h3CVlY9sW\n3U1O53m4MCAIMCoa0m5Cb/72b+Dl/h2GQcl0EEuhEVkjfTTFtF81CNnMX3e67HjUGEAU1KHuhbig\nJadBOT+n/kpduRid1kr46NGt1mhkkojGajVvjFGp/L13uJLGv6t1V9LgRGDiEvuKTjko3HBAn9+f\naVBeysF7HMStubuTpr8XyOI+LLLIIjN5EZYCM9CLdTB6QLhCESM0Qh8Ma56dTMRaZoarjQWbCJe1\n7sDYC+sxAmBuJBjTGq3nd85p5Dh6h8AORjRyY1Zamx8Jar6lDsaitcFVHQQjwiCIpTB5j15o0vb7\nHkOGzFb49sBRiEOF2mvqMUhwzI8TfG4Gs9oiCHg+BIApLRsimLZRayf6ULR7jJrznvYHrafnEJWR\nqduu4BsDl6HhkUvbPjcmqwQSkFOaslFLx8Nuj3B/wPhdMk3jNKFrM4uUQS9dp0M/5hA80DRohETW\n2ga7d/eaZ29/+RlGib4306Q8BSF4zb5c/fJLPPyQgmXjYYS3EVHclwjCTlyGw69HzQSwK9YYV+xc\ngAHY6Gc/DOCcJTpA8fCRq2AkMVxwCoFPgWI5/ugxHtL2Y79X69Sg1Mu4GOCDRyc1Il3XgZXjIGqg\nO/ZRQWlbv8JK3BFjEwtEXs9PA8Y+WQf7hztM2bokIOP8Jw7YiaXw7fdilV0gL0IpAIAAFNF7QLhM\nYMFoxIcKgdWU977QtFEM2GyhAzlEUvCTGxz2ud6gC8BaypBNo1HtxjsYO4GNYPcR4eVhIxRMORFp\n2iq5DGmVVMxiVSn1YxASGGC36zFIhDkw6UuYXragpuU49nAy4Kb9gOFeUHhxUBPVgDQdxSYpIW0A\nwlHNSj+MJSfLBCvgq8P9Dp0g8OLNFvb1tXb1nfqhFIZ0LbQVV905yTsMPyUT33//DnGYEGTwdl0L\nm/cdAjxnUBBp0ZUFEHsx91cd7NUGrVCFDZNDlJiKCQA0DmOUZu3+3XtwHqyREPyESDn2QUosQ0Ms\nsZOqPiByUcqpYK6AyeCpKA9X0KlsjBaKhRiP2sxX2YwQ1eXrD3tYGcitIW0qHDzDc8Ak713nutR0\nGEDbNlrv44gU0bo/ENYS02otwSAgaOygx9CnLMPknMZLmlWn7wU7p5PST+//wmIKDCBjzQ4eeFUQ\nyOofhahgLgQD7egzDhHdCth22SckjQ+4QBrY8aPHg/j6LTXoGqmLl+6/PgcX2YCzs101mCBj4H3O\nOZPCnCMbhOAxSBBx1zs8CF/hbnSYcs69gmLH4OGmEQfhQ+h3u6qG32lTU8SENUj3iBRzgRgxRUbM\nVXpNAw6l6pMrQAUrI60FixLgtkHbtIUXcHJwEP52axCDzGAcdWYc3t1jkhhC4zwQonavMm1TkHtE\nIPGJ2djCSNQ0MLe3stjCjQ4P0uDWNm1h3vITSJR3e7XWSsQk8lwPAwIHDTQCpL0+ePIVzIRKrxAU\npGAqRTQVVJ1VKXKkgl8g0liJaWyKI8TCi1kzrGe0ZH/Yo9lIQZg10M4jlKD1OcYxTUYh9I0xml5u\njEGTC9c4wGZrjiNM9ImTFMLulHlB1yuspdXfqlvpvoaxVwvip4cDLpUlprDIIovM5EVYCkCxeA8e\nGMUKWDWpZgFIlnwuKY2sRMYYJ0Y3ACvBzq86oBF047qzcNIkZBhYZ+C3P+7ENZD0XABWOePRxVyG\nkNpv5DhCqLBmkcGU2YMZ/RRw6NO+d4PHXo4zBVJGphCE8h3C4rPfYS8RYTdOpUNR1a0IAcrRZ0DK\n/UiClc8YfaJG+Qr95LQ4x6473HyeUISWgu6XowMh4lb6C77//kf14/09F75DZsR8LbseQWYdPzkk\nrJNYJ41VvkUiaBo3tA0ghoLZbrUhbehHuGHQ54nKdzfrBkbQme2bW60w4Mhw4n4475JlpfUnqNwE\nqqsSCgUbl0I1MgZ1x1mmkoaGaUovUrACrtyUGJfVzUDtpZVMRL/fa0rTM6Pd5ExMASXpCWdLJZQi\nJmJoYxjiCPiccZqEWVze8/UaVzfJ8mo3W6zkpe2sUWvGjwe8lZTk7767HLz0YpRCNu0GBvYyJjYR\naHNMgIGQB1gEJnkixhHsADSyYttGtKIUrCE061wxaSBZG7jR4e2PEqTZTXj1OuD1m+KHZ+48GFJF\nQCEmwlcAAQ5OFNdhdNj3Hvsx044xfN6eLKBKIWCSFNru7h7793cYDhmDEFRhjP0EJ66IiSg465pa\nzgDJZBZN5pziIWzXwI+5hh/wOXVqqCgRMOh2g3//v/4vAID/53//j3j7VUK+hdHB3wtmIESFg3OM\nSmQS+gExsEKz3eT1PJkrcoz1Cp1Amzc3NzhIetF7D7IWTa4G9IXMhtoGbU5drldwYvb27+8LotQw\nIqEEDrnq/mSbwgJMpCQ3cSpBS2UoyYjQFjCCFmXo+ETwATEr0pyOLGEcVThsUFyOcQDus2sZ0DlR\nCl0jBXVynSiKgJ1XUt3oQtVWwIN9CWgTGXRZyay26pptNiusc6AWAYNL8YP97i1+901Cfb77aUlJ\nLrLIIh8pL8JSSOE8ySwA2IvJ/yoW6yByKal2UaLUSIQ7ZkwMzYBMFBLJ3W6M9lddr6D8Bf2eMQ5J\nm98/jNjvHSaZXb/4RdXtiQNgxHyLFlN2RaaAXiyDw+AxuAiXA13GgqRcmYkQxU1xo8NBAmv37+4x\n7EeNmIcQEIVazI1TASIxqVmdaiyyK8MgjjNafOsL85TRTAxjyNH/tsMkxVF+mDC8v8c//V//JR1z\n38ML1VlrrFJ3Oec10Nh2VVPdVQeevM6Uky8FXaaq7TeGtOiKrdW+jBExAYbyjEhWKfja1UrN/8P7\nO234Ev0AK7lqthFooYAxBpTg9fr2FqyNdYAgz+nh+x901gcSMpBMLkjzIPmt6VpNT7MvhU4xRpjW\nohFg1Tg4xKp9gLa551iIYw97OAGF2baBaW2xiDgqSo99UPcreK+p6uijWkC2aXF9c41rof9//eY1\nXr1O7sPVtkMr1YIxjDgcUnr22+//gH/5KlkKbrg80PgilMLM02Jgn9N7jhSzYMGQMQlfKQVjgMkB\nuT2BbVjNfOaIqyvJhbeMTlyM5lWDVmjcd/uI4eDx+98n8+ph5/D5l2kgrTdrsNyicfTY79JB+95j\nzOQbgRIffyYgaRolyQgRim7s95NCTcfRIwbMUmdZQXCs8+kljRlAqiw8AgwzTCaWoag9BEIwipoj\nC0CauMbGKqyXOcLve/zm//j7tI0PWIu/3zQtRk4vUIxRlTVQ+hlwhnJrs4ug9zw1US3MwQfheWCU\n1dkYcMVP4X3Ua3NuQi8cEsysbpUPHsYJ9+TtNdZvbjDuS4wjK6/dsAdkIIIZUGbkoBDlVLxY3rrg\nA4KkRJ13Gp/hGKtqWAIMlQKthtAIrNY7VynyoIokjBGTVDISAbYtCpuYi/sQCow3czGmlSxWAvm+\nefUGb958hs/eJEXw+tU1riXL0bUGLNDRvr/HDz8mV/Af/vm3+DpjSSRrcYks7sMiiywykxdhKXDK\nwssytAHJ/QRscqFKp3Eh4QUoTEepRjX9RvtSkuyD0+DazXWDlfAcNNbj6kaWNxb7g8VP36f1/uW3\nd/jq98nM77pW50nnos76HEsw0liCbRsNwrGpMw6MSSq9xiFos1JGYuDRfHokGC5ZBp3FYsXUw6Xe\ngplgGNqbMoJg80TNUbEdDaCNVW3baA+JaBJPwFoQhm4a9Zi793fqZiBGbXLipwkuUxOHKFR1GcNR\n8CDMAdkq9/1BQTmr65vCaNRaxMaWIOY0wUghx3C4R5BAK1cZjkiEKDuegsP65hadzJQ4DDC+ZAVy\nAM4NE/YSYAvBq9WTWL659PRgAqnJjoJ2rZ5RAAAPZf0ma9TMD95rQDN4p4gI05SOUCFGYGLFdkAK\n6dKNKrUrxlp0QoF3ffsGr96kQq/Xr25xe73FrXBKbNeNdlJjdhikIO3t+7f4rbgM/+333+BBLKAM\nbrtEXoRSSP6oQgR1IDx44FpwPI0pY4VRBZLlvzy+uIo9JKtMzEcfcCOQ582ahUchdbu2N0bTcMNk\n8Pa79PK/HwYMMlg7EDa5EtMatCbTuRGsrWIPBAjHCKbASmfmIypDnJI/nCnckGjCgaQUCqBwXvOf\nDTuS682ZERMLBNyAYTLqjh2ajLrjoWIzjvDDhCuhOqOOFFHpp8JsTGD1j5kjSItzDJhLGg6VmQ0q\nRCBhCvB3OVbilVvBrjfwkZWKnw1pdtF7n8xxuZkKXqLiSnkXUvcmUR7TMGhLuzQIc3FaRMhNfggF\ncAYh9dH7TzBUlEppxgLNqkRQ6e6ERECjJx09gi/Q7KjK2sKaXJCWJqtQFUHlZ2tBWIsiePXmM3z2\nRSKcef36Na6Fj2O7XmHVGjRZ4yLo9Xs/4eEhVWl++/03+PVXXwEA/vB2p+8/F0TXs7K4D4sssshM\nXoSlcCzai4+BB+kruWpQIpIMJWolAuC5gFwIYK2WZfiQZxcubdFvGCtpVtu0qTnEqkufv/hFhyCl\nw8PdhMMhbbOfou5rFVhZem0wgIl6/IDKUmBWtiWgROXzUg68WWMUMMOoLIoKsMVctH3qPF4zRZAS\n3zKV9ThGBR+BocdAZEQ/4rvf/AsAYPv5rUbPQ3QalTeWEKugLdmcCeLk2iiYLKh1Y8AK0jHGqknn\n3aiBtbZrwc4obJuQ6OYAYHIe0Qf9Ph/DtC1iLtSaHNBMGPrS/1Lz903hLLCtQStAqIm9lkFT5ESj\np01pjdLZma5VnEjCNuTrSkZDLhADJUgzkAKdmXchxqDuG7hwXhhrZ4AnGIu1FEe9efM5fvGLX8ny\nG1xdZeugzSRaKZDLAV6OM00eXqyToT/g3btU8PTbr77GP3+bgEoP/ajWiL6GF8iLUArMcRZTyBIY\n2EmuauuosDFXbndiVKdi84RKd1QDKUQPJ7UL02Qg7ODYXGX25XT312vgs18IpvxmhVe7tP3dncf+\nkElFAoZcaxATwYqvlEJB1FexDlTnLBiYYqaxvv22YgCusw/1voA0+Eptv9GHnhREdhnS/QEAb8rA\nZU6J3uwOuMOhynigZC8MVS8Va7YkuRelryFbWxWRBTS5fyGXrlgcuTRCQfLrs5syHXqliqPImr1g\nZnUFKUS9gXHyCOFQUJBk1P0JqBr7dFZ5HZuVxahdupMKz0qBVi0g8Saz7rCWjFXjvcY3/OQRXCyU\n78FhkuKkWNGmASjVsD4iSFagXRHarsNWBvyrz77EF1+kBjivX73CjbgJ61WlCBA0a+Bcal6jXcX8\nhEkavOx29/j2DymO8Juvv8M3wouZqmAvdxuyLO7DIossMpMXYSkU6BKQoUx5acxBRwesM3rYQJmJ\nieRfKKaoRqwjlwYsVdDReaCXWoVNH3F1zVits8nc4jpnJtbA+ip9f31jsdunme5wiNgfhER08Ohd\n1IBk4NK1zxBr7YQh0qi8Bc/MuRnXAkhZpwmoLIVyXwxSC7hypNrSKnRwKeiYwR1Q+DcLc1STGaSd\n0+2tNZpnT3y0ejVgcSWoMQJcyqYHlV4P0SjxqTVG2YXItLAC6hruD3DOa5SfOWpAz1iroCxjrFoa\nnoP6ZeSDBB6TkDXKW8AH0urBpmlKgI2BXCrdrAxs26CT7IuPQbcxjdHKUqIGrVJ8jYhxLJ27x0nr\nINIlluNQFUDOfBbX16/xxS/+Cm8+/wIAcHtzg61UNm7WjRIJxziil9oVN41aPTtOA5wbNQgbvMcg\nZLU/vfsRvxU263/57ic89Dk4XHpPfoi8EKUAzGLzpfOmds7Zeca1oJe6JqEay1Z1XJ/0pXIg1JkY\nzQDGCJ9TYM6j7yM2W3EfNhErSXVtNw060UTrNWEjLsc4AsMosYZDxMM+4H7vZH+MSVyeyCjm98xA\nF9P8SBXmbTR2UA37+uEyoigZUX5gbQwTiQrSrxo4qatVHnhpz1FVaIWcjIkABkgRdqrGlKkKsgxV\n4CtCKUKytqK193r/g3fohzu9/0ykyEHTFMBT3WA1EheXwUel0ys+mZx/KP5kakibll0/lPoEQNOB\n1hrYGEojV2tUKWF0uq8Qi1Lf7R4Qp6CUdtH72VuXjW5jLNYbiQlc35aU4mdvcH19g7WwNq9XLazJ\n2ZNeB3/f79EP0tWpHzDmkno3psyGKCI3Tbg/JGDYtz/+iK++TyCl7x/62fv3eIQ8L/QhqYo/lhgy\nfDRkqiWZwUF4JS7pL69IUzOWgJVRvhB0DUGaI6M10GBWa0nZgawpNTPWpoGXiSnalrBapeX1VYf1\nVVIQTdcpUtEHwiQB0HGMmCbG0GfkosdBINS7PuCQ02aBdbA2TZPOSwOHVGDCXAKQNRbgOFBpiBKB\nKtK1mPqe5e2JdCAQEawGAE3aPlsxpijSOvYBZh1URBWJLSVSE52EGYoWbLpOB/jwcECsMQf5vBoD\n2zVopL9Ed7XR7tIxxEQaggQN16xfrFKgbEQRlVujFg2ZYsDUxkysyHpNXqcEfGxWSoaEvxGgxmJz\nLd2kfcT+7kFjFxwZRqyAbrXG9iohDa9vX2n14ubqWpVA1zWJkj2na/2EaZJir8MeB6nW2+122vXa\nO6dxl8CJ1zNTxO+HEe+kFdz37+/x9kGIf13QZsUstmZaZjBfFm5cYgqLLLLITF6EpUCaKzv5q/4v\nWUN8sQJuN3nb9H2mgu8sQciEcXNtNNXFIbFAA8CqKynA4jGLFUHaSwW2a5QOrOks1pK2Wm1a7aJk\nbYMQgSCuTXCsJrN3jFHcjEMfsM/LE2MYPcYxIy9RelEyV6k6o+ZrSinmWEGybnTmQ7EITOV0EJWu\nVvX6lNehnPEozXeNNTpTxFCKnpq2QSPZg8QfwMp2ZGwBfxlrdRs3TmopxOr8bdOkjk9Sb+FjVLPc\nNo0iLYdhwDRkc50r1GQ699mrWzd2ydalscpuFGOoagrkvuTzscW6iJXL0Kw6kPI1EqKLaIVCbb29\nwvbmFYDUp3Mj17JarzR7k9Ccmb7Nw00DBunz2fc7HKT7VX/Yodfai8IAHjmmuggkGn8XAnpJid73\nA36SWpr3uwEHyd7MQXJziRwvshReUEzhecmVdHeTZpCwaggTiikbwYCgdEFRu03FIJ2ckHzFDL+1\nYpVbRb6Rml8UIihjrg8Rd+/TjTd2RCvNWTebFqtNi7VUbq3WjZrllghWuB+JCSGKWT1GHPqA3S7t\n7/4+VWoCieMx0xEkn72kJOc5Z1aXIVYBRQKUip2IKlcA2oRVLeecrgVgYvbPQ3ErQDqQIwMulLQb\nuIpXRFal4kNVEASohq0DwIGkW9LQ67nl5zdOB0UhbrYbjVWMg0PML8D8DzgW5CdzKShiAKwIwPk6\nSWHmgHTF52BIXTZLNjX/BdC0a2y219hK1We7XquSNNYU14yCpg2n3sFJ2nIYDhj7HXpRCuMwKBnO\n5JxWkIaqnR3HshyYMXiPnXB+PvQDHoR0pncB5dYcu+EfHlNY3IdFFllkJn8x7kNaysFFwq2Y+J9v\nCNaw8iY0VvuCoLPAKjdGMaUVfWMKeXEjs6ki8kwxxWtQEOr6DKryAkSw1miD0NW60Rbpm02Drbgc\n21WLTmYWaxowE7y4HN4TdmIpHHYeB1ne9ROGXHo9BoxaRhyTmVzdNS1OqmZ3QqFwA1DQeURV2DJf\nBuk66orUwUgypaGtpLqUiJYKYKhp2xLpNKQowjqXEiWsrO5QY9HKvXHeo5HsRbde6THGYYLLBWUh\nMy1JloULsCotlzqGQss/D7pRdT6GjB5/vVljI8i2zfYKa1lu1xs03QpNNlGJFLDkg0tFZQD8OMJJ\nV6pp7DFJ2tBNE5x3mkHxIWiBmA+hsETXjW+ZNRPkQ0DvHO7EOni3O+BOWMOnUFLvpQgF+jzzH87s\nvs/IC1EKhi8zcGoTOX3zqgVer+fZiPxba4pSWNkqVkCs5p41gi7UgYAC06XC0SgnKn9qpXBkbJEp\nvrMx6OQFv9o2uBVNdnO9xmazwUr8U2NaBSpHT/qCRxhA3I/RMd4LTffDw4D7hwN20j1qGJ2yW0dm\nTTUyl2up8dPJrTBz1+LRXZ4rAlNlMjgyQojVeZZ7Y6zRrkbXr681Wh5cmKn31G0pU7iVQQ1AU5pN\nYzVWkStLgUJKM0uJKrSbFVKalEOl4HKGp2mwXq1xdSUDvm2xWqc4xmazQSfUbLZp9GViomTaZxSm\nK4jCcSypw7EfVUFMvmQPFIifYx9cUr8hlspWRhngXFW8Tj5gPwx4J5R27w4j+ukETgLzcV90BSHG\ny5TC4j4sssgiM/mLtBTSkuAPCPisKxkHQ9DiIGMqV8KUFve2cjGMBOFn/U+yK0GE3HfBUG1NmFlg\niiqTjSsgS/I9snVj0EoR16oDNusOVwKouLpa4+pKZqr1GmuZqdp2rdwAZFow51w+MI0ee7EU7t7f\n4/4+WRGHfsJeIvbD6JXDwYVS0MU8N5+pQksCc5xDoVmrLdOceajM94yIbIya2NevrhUFOY1O2aUA\nktk9fZqjM6EHarpWXQkyRvEP3gdwKKxMkWPBU3CxCBrTqMu2XhcLYLVOllrGEBhjZsCsLD54DQYO\n44B+GHCQTl790GvGxPtJi+28j6VpD6PURBDPLLJk0fGj5ToAHMFqafWTw/2hVzzCfgzwikfgmZ1w\neiQR+MLsw1+YUtAtZqCmlWF8tknXe9VVbxvKYG+OYgpNFVOg6oW3lpDxyBxR+Z2kZpWt4g7ZrKbK\ntchJvZT2KylFVRCUjttIYKOxBk1T0qUbeVm3V2tc3yQTd7u9wkoi4V3TwdpGswwxVtWgPnVcAoDD\nOGGUVMYwOuyFPOXh/gFTTSsfQmmkGgofBVClNKlE2EEkEPJs51YKperqtLlaq36MPhT/Vp52HggM\naOzDmkKc0a1Wuo2bvMYUiAzWqzW2ghxsm7bKmBjl4uy6lSqCbt2VDuBGuBKpnJByQASPSSL849Br\n2nC326HvB4yiCKY6dYiS8ZihWKvBzuCsF07+ln+pJ5jAEYPL8aUR7/c9HvrcPqCquNR9PCWXK4XF\nfVhkkUVm8hdqKQB10NGAcSVMSr+8InRiprsqrU5UQZsJszJsoLgGbQesN1IoNEZkns5k+hXrIPe4\nTFgElMAlGS1oSoHKbB1U2QsJK5rautAiHK4sEqsWRNs22Eg7tc12g+12g42wDW3WGy3csU0DyhYE\nQyPcITJ8bgF36DENY+rXgGSOe7lZ0+QxZhYm57WILFaw5hAZIVRw2gqYBGOqZShlGc3uBSVsSHYN\nyOjjtzBaem2tUfepaRtYIcddb6/QrlZoO3GzbKtuTrLO8qkYBR+xKXOpjxHee80MjH1fgobDgEka\n44zjiFGsrnFKloHL5eMcS7Eal5k6FSsXC6AUZOVXvLIoKnesjmfnG+18xINwRrzfD3gYnNY1zIOL\nz4+eVN/yr9p9AObxhZJxuG2Az7fZ30eF3UdlCh/FEIDK/AcqBjBt+sJVfKBOYTbiPjTmscJIFHLZ\nvz1CGqKqRajSiMl3z9+bqvah+t6kVGOuRVh1HVYrWV51aIX2bNV1MNLZ2BirmRRr7ExJEZvi30fW\ntFnqnlWi+lpoxYlWLOrnHEuRdCNXgyXDO8lU2RsZFKZsn+9NYyy6RmoiulYBQrZt9HqNbUC2KVR1\n1asTQ9QaCR+cMlBPfsIk3Z4m59OAH0u8wMngd86rH1+DoqIQ5uTP/mjcxAx+w1wplJSg0gCV/8sc\nMesepfUN/YQ7oeh/6B1Gz1ogyJVrBz4ut3ssRGbJPiyyyCIfJy/EUngKvPTs1gCqICAxbmWmv13R\nrMbhRMFhidZWn0vF3XwW0pkOXIGFJPCoGYviSjRHbkZZx8hn+c0UrW+IZu5HtjRsBcvlfC4avZ/b\nTVTtN3cgto3VSsSua7FatWi7PCOv0IpFYW1T8vlUqgcb25SS9ozTyK3cqyxNZMALPn9yDl5qH8gY\nnfWbtoWp2rsxaNZ0JV+LNUaPT1UZeAb1hAr8k/uETsOo5v80jZjEFRqnSasvJx/gQqhAQuU515ZO\nAogVq0fvPY7eC1SZhMplmM3eVKyh9Jk1WM5U2hP6GNFLe8H7/YhdDiyqlZD3XblpqJihz8q/+uzD\nbGvUiRhCKY561QKbipilVgoVgO/0LmVh/mCp/iNr0NwdQRn8CUhVtjHVwE/goTL4ba0UKqViNape\nIvTGzF4vRCb47OumyiM55tz10JiIIYmFSBzFWrS5iKdp0IiZ3jZWi3u6ttP0oLVmliIEGZhcb2EK\n0VxkhpcMhwtBTeSuW6FtO6Vna5pSLxKZ4abCLJ3N/+gDfC4jDgHOFzPfu6ixj8QGndeLQkkGOB/g\nYkYTJlBQSQnOBz3r99XT53m6L87ejUKaM0tDzoSO3psSk4gAJsn+DJPDXlCLh8Frs+Vw9KLWpDvl\nzJ8S868V0XiZ5EKhFTGucgfqlmCy1UBzBfHoyNWtO1eBPhtwR9/nz4bqF6EEEDOisI5naHfpOl5h\nCLZKY2al0MiAzjM6VeCKCIYL5aVWnIEpxyCxUvR8MA+iZoMgKbS8vZlZQyBb7Rt60kSmwjYUTVzH\nxUig4Y1YJ421sE2xCLLV4JzDKO3snPdlBpegaX5uiW5d7nKFjgwxanrVV126feSZUmCgxEtQFU5h\nlt1Ov+bPVFREPXHUqcZHQtVNQLFCnI84yHXuhwn9mLElPFcGxxDmclqomT3PycKnsMgii3yUvCBL\nIcvPPZ9qpkYplNo2pS9lW7kSBABUmWJVvKE+k5mxduwfzg9fFqs4QInPF5dDo/+osh+A4NM3AAAV\nt0lEQVRA5VbUzEtlObsltTtis9VQdaiqfWVTxTDMkaWQYjLl+vU8q2tJTWrqLcr/xTs+uk+P7lF2\n8dLdUwCYKa5UsobKftXEj6VJUJrBS8TdkNHj101WUk1B+t7HiKD7ShaVsm4fPWiuLYjKLaDKnajn\nXKq2ARULAPRox7P7lBsF9aNTS+Ewhpmlx/VTOmspHGcfZuZFtdpfXEyhDJ7LFMNT/lQ1kOSvJcY6\nd6Nu6uKofA7loR45f+UQtbJ4dHureMMJ16LOnz/esvyWCVTyvuYvQqUsqm8NGYV2E5UOyMmHLydN\nj5RCOWc6tXx0nsXFoVns5FgpzNRCpUnPvWuVJa77BgRnkN2S+uWWYJ4es4oJRI462IO4CUDiIwi6\nPsuAO+EmzAbuMTsBVbeTq+8rRUJQkpz6juQl8WAwhYih6lzeu+wy4MhFyed83j1Ix6dq+fR9XtyH\nRRZZ5KPkhTAv1dbBRcrsYtFgEgO9mmXAJveItLlxbWUSZDo0ohmbcQmUHZ9uXSNQB6BqOTas55ZO\nVuKReEbcWotmTFhYjfR8ShpvFgAN1V5ql0csjZp3QWcHmgck566EzODIdHAn9l2f72x2P7ognpvm\nuk2CR6bjVClZQ8eWVl1iXC1XgcIImrkINRCJj0zu2uqov+PKBTCAnvRszqXZHqpjzt+AyFy5DF5d\nhmGKpbjpeJK/yGiuaHvPWv6Xj6sXohRqudSdeWq9xz4Vg7R+fQhQs3LLhK6pYM9nbh4dvdBVqCDb\nbLIenxwgwNHLn3NcyKafvuHat4FRm6LVAJMBqm5CbcpyMf94psnKPrJTUccxynkVvsL611MuRu0a\n1EqpPmf9xVQ3TeYAnn9UMYXZBkR1v6zyt8YQxDorgHp4VngCrgYrTkg+TVP1k3i0t3o2qBXw/Apq\nnELhgGBMPmIYc4FalW6M9VHqZzmfSE6e8KPP513pS2VxHxZZZJGZvEBL4VPLbA4CkEz0KbP2uIRp\nz5kJSwUnUFv8s9n0kSVbxUkjzaLOp2OW1RSJNNMXtCLhJL6zNlGP3It0muVTPbfprmorJWce8ow2\ns3Si9lrgo5lx5j48usbarqjCjTkrUsEu6ej66x4Oc/zH0SxX4QfONTqpr7meZ+frUG04idWUWZlM\nYWNurWI2YgwIVYEYxyp/UbkmtZ/JsXBYjFPAYQwYphJQrF2eU/KknVBhU5L7ec4Oyq6wxaXyApXC\nrFwMl7sTF0iFWMoP1DHAvhT3rBpCW1G7zbc/OrXq+7NGmr7t5REXJVAZqlSWT7uFlVuiEOc8+Aiz\ngah7mg/qoiDERandBx2nVelOFeGnShFks5hmO36s/QgAKcnI7ASOTqi6/qO0W63qHhUc6oFODx8+\n87yI0m81mCy3bbOWsBIY7OZqjU4KzcARfpow9pmduUC4Q4jqMkUuTXGdjwpEOowBo5vHDp7nQLhs\nHdSu3Jn9Pg+DLrK4D4sssshMXoilcCa4h09qJ+DRdCHfOIaWCPtYGtmumorard6ceDajzef8anal\nuSsxa0YyC1jVZ8gzrV9N4dXxTpuIurNqRp5bDqzfMmI1ldJs+zp/P7tmNffp6DDnntT8+o9NrZkN\nUwUEawOiNptqt6A+5swiqo83WyzWBEMyLNnQMIARs7BpLTrp6dGuDNq1lGuTQdsxrM07DRg4F3GV\nEn3vgxKq1u7CFNI6CkaqAreXz+LH4+TUvf35I+YFKoXiMnxqhXAaPJOOHWSAjMwIKVOEwIRsPbam\nijU88nWrr+j4h/pTGeBxtmqJKdToOKZKAXCtSPIgqP346pfKd5+z9+Ulnrk8M9Mcc4V36lkQSLs0\n6UljtoL+rUE1NcTpbGC90g/z5WOjuNR1gKqrrOM7s1Mq3+sblj9TueeRA7y8ADFaxAwCNHKfcjbE\nlIImHwIGcSX6IWAvnb8GF7VQLd2vYph/iDk/l7y/06PjXOaL6HKn4IUohU87/D/82CVoE8G54zmi\nZ/iYYw1Am1GQKBbEfHiW7/Ke52OythrmgYi6QKueEvn4d8gLzGWQRZRUKoOrd690keKjUZjiCI8V\nxhwyexQsOTa06mBjtXQiijH/JAO8png8xm3oTvOzQDmvsm7pKXH6JCv9REdnONuEEZRMJyKGXIbd\nKwmtsZTWy8Vao0c/pPTi/uCw73NLwKgwZV+R20IDgz/nXf/4GMQSU1hkkUU+Wl6gpXAujv8xWvbS\nbU6Xk3Ada2CglXL0VUURn5vJnDx6NTk/OhM6AtzkIP3Zybme3bJbUGcP0pp1W3lG3WTl8X2tKd5n\n80jlSsy2OsqvzmMfZeNHSMb8t7rgWP06A1nNdnX+vaD6G45zS6visCiWwrGHV+5/thEBgD0pT4Mb\neZbBiFyYrscpoM9uwhgxumwdVN2aMHef/ngW8SXv+eXHfiFK4Sk5pyQ+tTy+aQwg9zXiyOofugis\nTOVWmCp9eebez15iwtyn5gLHNnxMxpHEGFRs8ZyUiLzVdU+GxgKNaKwYSWG1HI59kRJjmXW8mt2A\nY2WZRxGl/gr14D9SDOncSWHCxNC03fEtmnlWdOTVyLI5YikgVMp4dnPnDgxV35XlVL3K9fr6LFj7\nU0RUAcSYEIkZhThMtSKY0+IX5GbEXPH9OeTDx8/iPiyyyCIzeYGWwrFKraeNbBY+1mXnEV3PTOEX\nnk+KWKd9TVVJroupX6VksVKW4sSkMbP+xUqoyxqKmcuns3hcmJfahhJXQI6IVuuHCOW2N9aUfdVA\nJD52DWqz5dhMz9dfkJaRGUy1y3EUJqRqoXKftCbjaCuxW/Tc5gHYOkBYgqmmMiOo3tdRQLdsi9n1\ncpX+YVBxmSrz38eKJs1FDFNUinUX6iIsmt3Np8yC+houk/Pvb/nl3L4+LrD5IpTCPHU2/2XuldKJ\n5Z9/9MuiunMJOkBSvGGSL9YNKUdkYzELkM+G3dHnU0NyhlRkgOUF9QylVANSZkEj+aG4OVS7DFy9\ntqJ4TmQecS4m8Ci5yfMsw5mYt2oIRt3nYH6hhDrdeyQV8e48gl6lcQlz2PXJYxStrNRrmi4s4zjE\n8iwHx4o5mHzqwlUqIMsduSReUFeoPrc6VXt8SiWcuutUvU2XK565LO7DIossMpMXYSkAlxr5WbMX\nHfo0KONTR3fqubFMQ76q5/eONTOxigX81FQUcIbmlcRUuRazCbOe/arZLGYyhROXl2ZUOcdHs+eR\nuT0DCtTXVu+s3nc2948O/GiWPzXt81mrekZtdrQpnfitAEPzQn2dJ82fR2cXUKw9Hwo12ugYQ20d\niGkQWZ55zeOn7sMl71netrZ8z62a73N9kPn6Z+3bqlCK+ONshRdBx2bIfMTp18OI8fEK4OP8rvN7\nK6+lJVZXYmVK3KExBGN4xo6cVdu8uzP0Muvva1qCo9WO/Y/Tl3Y08ua8CxXukI9f4fKycvXtU67c\naXTl0bnTPJNwlv/y6GLq+1CP1dr8rk8xL0YGJseaPRgdVBG4ULo/cVYEevRjt/VD3pvja3pq2+Oi\nwFPrn364x7R19T4vpXhf3IdFFllkJi/CfXgqVvu8Nv45VsKnl3Q2ZaYRHAzGyLCy3BlgbQtsuqnq\nKpqj7IWZzXqs39ORRZEXG0OgCjRRyo2P6hvqrQizObx0PeQz5cfl+o63mQfh56Gy+fnOA3XzoGcV\nXKz2W+yTbMKUQGPtIJWuTqRNcENkzRwMYiVIz5gEOJJDz4FHtRzP2DRzXZ+HET9tVWmWheuZ/ryk\nS67m9BNm49ziushISGu+RPdhZv49mW7J8ue/hrkU12b+skuqEEkJNKoISOMQnU3/AKA1pXMUVWWa\neRDNTObKtZDucKjJnGu6+Ux9Xp1lRSFWtkmhhsfmaNFN9UAs29RP49RQeGQIz1yGKvtxRE1X72Hu\nGpQLjczwonxdAMapKAJVApzp7x+PJH50puffv7lSCGfWe7RVfQXle91XmQifZHCedTE/LwpQAyGy\nX9yHRRZZ5MPlZVgKpjl9EhwfadTT8qmthjJrffCWMw1eUgYnOgjo/hOzcjlyo1YDQbreoa3qLdpc\n31Dl8LXhLXHVl7IyyyurIc/smg2pzmxmKcyuC5rfP1VdSScshRSxV59ltjNGxVpdFSbMHUaq3J9S\nocHIdQjpNx8SXwEAOA+4CmBUsgfVvjD/eyZki6ef/8dZCs9LdU+ffPufckMq667mo7gw0PgiYgrn\nbn4d8X5qvZclc+P5PKynGKrxaDNfxSGyWJT6CmuSguiqmEQr5B+Nma9Xmt3MD8KVXzMzUo/COKf8\naspIxVp3Pg4pzDJws2fJR0Z6XShlilaJnNOvKSbgKrfA+fLZB8xTh3rMoyaws4us/55yeC6Rao+f\nhCsh7bOgOM9xix9v8phropyXLl18Bi/CUrisFX39th4rir80xXFK6hf18Vx2/EipCkKmjtSiFCjF\nKIBkXWh8wtY09qnAKldT1nyRRxNNOYMqvqBDbdb3oayvZ8/V8hGNeQQKQSwXzEBgIMiE5kOJA7hq\n4AcZ+POg4OPnzqjb9tXK51O/I7XVwD9TKRzHFy4Qznf0xHnpokGMS0xhkUUW+Qj5C7IUKr33yFR7\nfvPL6itegjx1PnT06fF6aaIv8YW8Td3i3lJ2OdLnxuQuWU9nNbJlYXNGoA6dyGJk1n6JdYPbGMty\niJIBiOWzrldlBWaWBh9nBubW4en4wOP1LpOfs82nfJeOYFzHZlyWM5bCMR3fpQ1mX0hM4TKpLu+J\ntU4/0D//sL9U+Vx+pqfCYzV5Cbh8H6oCJiIGAkDCRWlQcw3UfujRK6jKQtav/NU6pVn3MZ19X597\ndT5PXfFpXzndS6qiqOe4Gj4qWKwLZRCm6zi+4x8eizjVn2N+1OOY1KltT5wwP7fe5fdhcR8WWWSR\nmbwQS+GcVXOs3bJZeVmiZt7h6PQ2L815eHwvLpuN5nP901vw0az6aJ0PviGnn9PTa9frlLmpRifO\ndzMLYab/q/fgfL3Eh0uxRz59APs5x/CjjjLbqPL/6sLBD9jdi4gpnMMpXBovOC/nhvynVgU/f3/n\nIs5Pk8d86mv4U8mHu39/HjmV5aq/ey7LcPkzupx8pQzy087x+WMy80UPeXEfFllkkZm8DPfhTAOP\nTyN/jKhwvd/55zovnnLWP+e4f6qZ8kNv/lMuzvGaNaqpZBXOyyXX/CFW0s95/pX5LZZc1eTrk5Kx\n1o7QqW/TMY9BJKcyDj//rXkZSgHnCDguSc09HV+o/cPT0d6n9/G8nDLrf+a+1ec/Z55+ag36ERF6\nMiiD/KlYR8mE/CUKPVpKMMrLFMJl7+a5Yz7OLtGZX09v//Ra52VxHxZZZJGZvBhL4dhMS18fF0Q9\nXuepYOSjLO8Z6rbLy17L2T4RzMHzAahz2+HCbS8LRl227sfJzw8C/6nkw4Kaj9EH2dL5VAVPp8+K\nZpVr+ZjzUOLMPmTgOavhY5/Oi1AKpwEqTyfgLhM68vFP7OMD7txlBtvHyR8r8vHHk1Nu06nvP3Sd\n4/V/7h35sGM+XuuPp2Cp6kA9P86JCfL4XAiqNI6TjifzbR/QYHZxHxZZZJGZvAhLYRYE5NPlxjNC\nypNVaCdAGuew4mf38XiPl89pTzkVz+/r085Bf2x7409pz5yzwv60eAYBVp8NAp5HwzxxbvRo4dwK\nj4WPF0tI/fR2l1uzL0IpgGZdCQthR+1JHcUajh/LyXr2MwP/OfTbh3fxeX49vlAtfJjB/JKAPp/+\n+I9ScI8OOav0OLWHT3AWZcgRSN/D0wnpE9vOUJdH8Qp9P+kopnD+XC7nggSIbBWeuPz5vAylMJMC\n06TH4ZX0/aOXhU78/vj72fofETh6yju9RC1cIk+vdXwGfwxF8KmRkrV82H7rIqTjszqv2M/FkQqw\ngJ+5fwVbcdnQv1QYT/n2JxT8RwMhTk0Wl+9riSksssgiM3mBlgJwXqt9KhRb8Q6fjgSc3u953Plf\nstTX9lLckudAUc/N3Efo0g8+/lPIzZ/rmjy//ePi6mIhP7n1iSahT9MNzOXlKQWOswF3Kd37aY68\n02mzlAEqvuExTuHs61PX7+czutDEO+5zcOrsntvDx6177kU+/f0x1f5LUXmXn0cNLT/PXnDJsWZ3\n6yiOVccXzgtV8OifSdEmbvXHVoN+yHNc3IdFFllkJi/CUmCuWHTIlPnp3IRd/a9pxxkp5+kE0bkA\n5DFV2xxUUs7xFPFn1uAXyRFC7ZzMUZ2nbKRThKSnYTfngGGP13v82/nZ9Y8ZjDxzxFNAnmezDx/b\njF22ftQs5mNm6WMg0sfO9PzISuAavHTqHTxqsXSpvAil8FhO+UTH31+Swjm9x9O/H6HFdOHpXIOm\nqp49wvFDPefaHO+r+ITzB3zpwHw+PlCuIX/+uQP+nIN0ieM0v67T5vJcjX3cuT/Vxvb8syyvxlPo\nhCe3vFjm13W8NMdMnEuJfowKWtyHRRZZZCYvwlI4h0d4CpF4et20N1KzstavBUjyKEj0ZD761PE/\nJgpduxlzUEs6hTOWz6zvfA1je6p71hHg5sRZH50ZHoPDntriafkYO2F2/eo9VujWR6b8PBz9Yedn\nnnT5Lt3baXfy6X1fJrVrnK8/zmlHCCh4nifO8cTSs0d/yXRsT8rJdmzA/IV5IlpcRYNP70OWTlSv\nPY4kP8/m97x/f/rRPqWS5oPsaSDO86nXD01DPoXCO32fnkKKzs/z8b4uOR/9/8RzPv2Ms7//AYN4\n9t5UR7644OiUkjud8ZCTK7+ciR3hUQyqWqfuBBYvaxu3uA+LLLLITF6E+zCXY1fiaVP9+fDeqU/z\n/T81i59iDH4UBcbzAa4Pz5Kf+nRsG5TZ8bwjcWkG4UONtfo5HS+f3+L8b5/SYr3EaK5mVAbmJnst\n2X2Letcfy4dnY873GD0+cnVfCSfcqOOtistF5073GXkRSiFd62OTv/48uxV1G6NTaqG2nuqvZvXn\n8zVOm+lPKaS5KTw3jZ+OQ5RzOqXkjmMApxTZo9fl5DGPY/Sz34iq9+sJ96n69jjnctr1nN+z587x\n6e2P5SkX63G85rRCfXys+jkQP/XUj/dY/fqMG17eiir29cS6Zbflzh3fQyornT+vj5DFfVhkkUVm\n8iICjbYKNJ6bZ2t5bi75mCt6LsdQr/NUiPDDwmIfts2nlEuP/+c+zw+Vj33+5/ZVy2Xh19OS3+un\nneHLj3PuuI8dObEvGAh8WaDxRSiFRRZZ5OXI4j4sssgiM1mUwiKLLDKTRSksssgiM1mUwiKLLDKT\nRSksssgiM1mUwiKLLDKTRSksssgiM1mUwiKLLDKTRSksssgiM1mUwiKLLDKTRSksssgiM1mUwiKL\nLDKTRSksssgiM1mUwiKLLDKTRSksssgiM1mUwiKLLDKTRSksssgiM1mUwiKLLDKTRSksssgiM1mU\nwiKLLDKTRSksssgiM1mUwiKLLDKTRSksssgiM/n/Af1RtaQilpwWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f045c5faa50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_training_data(batch_number, image_numbers=[]):\n",
    "    \"\"\"\n",
    "    Loads the training data from files. It is possible to specify an interval \n",
    "    of images to load, or by defauly load th entire batch.\n",
    "    \"\"\"\n",
    "    if image_numbers == []:\n",
    "        return np.load(\"./TensorFlow_data/training_data/training_images_batch\" + str(batch_number) + \".npy\")\n",
    "    else:\n",
    "        return np.load(\"./TensorFlow_data/training_data/training_images_batch\" + str(batch_number) + \".npy\")[image_numbers]\n",
    "    \n",
    "def load_training_labels(batch_number, image_numbers=[]):\n",
    "    \"\"\"\n",
    "    Loads the training data from files. It is possible to specify an interval \n",
    "    of images to load, or by defauly load th entire batch.\n",
    "    \"\"\"\n",
    "    if image_numbers == []:\n",
    "        return np.load(\"./TensorFlow_data/training_data/training_labels_batch\" + str(batch_number) + \".npy\")\n",
    "    else:\n",
    "        return np.load(\"./TensorFlow_data/training_data/training_labels_batch\" + str(batch_number) + \".npy\")[image_numbers]\n",
    "\n",
    "def display_image(imagearray):\n",
    "    array_to_plot = imagearray\n",
    "    print(\"Image shape: {}\".format(imagearray.shape))\n",
    "    plt.imshow(array_to_plot)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "display_image(load_training_data(0)[19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up functions necessary to build the neural network\n",
    "\n",
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, [None, image_shape[0], image_shape[1], image_shape[2]], name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, name=\"keep_prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution and Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"    \n",
    "    # Number of input colors\n",
    "    num_inputcolors = x_tensor.shape.as_list()[3]\n",
    "    \n",
    "    # Convolutional filter\n",
    "    W_conv= tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], num_inputcolors, conv_num_outputs], stddev=0.1))\n",
    "    b_conv = tf.Variable(tf.constant(0.1, shape=[conv_num_outputs]))\n",
    "    \n",
    "    convolution = tf.nn.conv2d(x_tensor, W_conv, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    h_conv = tf.nn.relu(convolution + b_conv)\n",
    "    \n",
    "    h_pool = tf.nn.max_pool(h_conv, ksize=[1, pool_ksize[0], pool_ksize[1], 1], \n",
    "                            strides=[1, pool_strides[0], pool_strides[1], 1], padding='SAME')\n",
    "    \n",
    "    return h_pool "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"    \n",
    "    flat_dimension = np.prod(x_tensor.shape.as_list()[1:])\n",
    "    x_flat = tf.reshape(x_tensor, [-1, flat_dimension])\n",
    "\n",
    "    return x_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully-Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"    \n",
    "    input_dimensions = x_tensor.shape.as_list()[1]    \n",
    "    W = tf.Variable(tf.truncated_normal([input_dimensions, num_outputs], stddev=0.1))\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[num_outputs]))\n",
    "    \n",
    "    h_connected = tf.nn.relu(tf.matmul(x_tensor, W) + b)\n",
    "    \n",
    "    return h_connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    input_dimensions = x_tensor.shape.as_list()[1]    \n",
    "    W = tf.Variable(tf.truncated_normal([input_dimensions, num_outputs], stddev=0.1))\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[num_outputs]))\n",
    "    \n",
    "    h_output = tf.matmul(x_tensor, W) + b \n",
    "    \n",
    "    return h_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    convlayer_1 = tf.nn.dropout(conv2d_maxpool(x, 20, (4, 4), (1, 1), (2, 2), (2, 2)), keep_prob)\n",
    "    #convlayer_1b = tf.nn.dropout(conv2d_maxpool(convlayer_1, 10, (4, 4), (1, 1), (2, 2), (1, 1)), keep_prob)\n",
    "    \n",
    "    convlayer_2 = tf.nn.dropout(conv2d_maxpool(convlayer_1, 30, (4, 4), (1, 1), (2, 2), (2, 2)), keep_prob)\n",
    "    #convlayer_2b = conv2d_maxpool(convlayer_2, 20, (1, 1), (1, 1), (1, 1), (1, 1))\n",
    "    \n",
    "    #convlayer_3 = tf.nn.dropout(conv2d_maxpool(convlayer_2, 60, (4, 4), (1, 1), (2, 2), (2, 2)), keep_prob)\n",
    "    #convlayer_3b = conv2d_maxpool(convlayer_3, 50, (1, 1), (1, 1), (1, 1), (1, 1))\n",
    "\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flattened_tensor = flatten(convlayer_2)\n",
    "    \n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    connlayer_1 = tf.nn.dropout(fully_conn(flattened_tensor, 100), keep_prob) #200 earlier\n",
    "    \n",
    "    connlayer_2 = tf.nn.dropout(fully_conn(connlayer_1, 30), keep_prob)\n",
    "    \n",
    "    #connlayer_3 = tf.nn.dropout(fully_conn(connlayer_2, 30), keep_prob)\n",
    "    \n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    outputlayer = output(connlayer_2, 3)\n",
    "\n",
    "    return outputlayer\n",
    "\n",
    "#=============================\n",
    "#  Build the Neural Network\n",
    "#=============================\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((150, 150, 3))\n",
    "y = neural_net_label_input(3)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "#logits = conv_net(x, keep_prob)\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "keep_probability = 0.5\n",
    "learning_rate = 0.001 # default is 0.001 N.B. it is also possible to make this a placeholder object!\n",
    "size_of_minibatch = 2**6\n",
    "\n",
    "#===============================\n",
    "# Don't need to edit below this\n",
    "#===============================\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print cost and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tensorflow_folder = \"./TensorFlow_data\"\n",
    "training_subfolder = \"/training_data\"\n",
    "training_folder = tensorflow_folder + training_subfolder\n",
    "num_saved_batches = sum([\"training_images_batch\" in filename \n",
    "                         for filename in list(os.walk(training_folder))[0][2]])\n",
    "\n",
    "# The final batch will be our validation set\n",
    "validation_inputarray = load_training_data(num_saved_batches - 1)\n",
    "validation_labels = load_training_labels(num_saved_batches - 1)\n",
    "\n",
    "def get_stats(session, feature_batch, label_batch, cost, accuracy, printout=True):\n",
    "    \"\"\"\n",
    "    Obtain information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    training_cost_value = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob:1.0})\n",
    "    validation_cost_value = session.run(cost, feed_dict={x: validation_inputarray,\n",
    "                                                         y: validation_labels, keep_prob:1.0})\n",
    "    accuracy_value = session.run(accuracy, feed_dict={x: validation_inputarray, \n",
    "                                                      y: validation_labels, keep_prob:1.0})\n",
    "    if printout:\n",
    "        print(\"\\nTraining Loss: {}\".format(training_cost_value))\n",
    "        print(\"Validation Loss: {}\".format(validation_cost_value))\n",
    "        print(\"Accuracy (validation): {}\".format(accuracy_value))\n",
    "    return training_cost_value, validation_cost_value, accuracy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_list(inputlist, batch_size):\n",
    "    \"\"\"\n",
    "    Returns the inputlist split into batches of maximal length batch_size.\n",
    "    Each element in the returned list (i.e. each batch) is itself a list.\n",
    "    \"\"\"\n",
    "    list_of_batches = [inputlist[ii: ii+batch_size] for ii in range(0, len(inputlist), batch_size)]\n",
    "    return list_of_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a folder into which we place the trained Neural Networks models\n",
    "foldername_trainedmmodels = \"./TensorFlow_data/trained_models\"\n",
    "if not os.path.exists(foldername_trainedmmodels):\n",
    "    os.makedirs(foldername_trainedmmodels)\n",
    "    \n",
    "currentmodel_name = \"lenet2x2\" # This means we have 2 convolutional layers and 2 fully connected layers\n",
    "savedmodel_path = foldername_trainedmmodels + \"/\" + currentmodel_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose which of the training or testing cells below to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on a single batch\n",
    "\n",
    "In order to pick the best hyperparameters, we begin by training on a single batch. This will tell us when to stop the learning and will help in choosing a learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch, i.e. number 0\n",
      "\n",
      "Training Loss: 1.49825143814\n",
      "Validation Loss: 1.48400425911\n",
      "Accuracy (validation): 0.219178080559\n",
      "\n",
      "Epoch  1, Batch 0: 0.219178080559 \n",
      "\n",
      "Training Loss: 1.07220578194\n",
      "Validation Loss: 1.08021247387\n",
      "Accuracy (validation): 0.383561640978\n",
      "\n",
      "Epoch  2, Batch 0: 0.383561640978 \n",
      "\n",
      "Training Loss: 1.0610691309\n",
      "Validation Loss: 1.06706500053\n",
      "Accuracy (validation): 0.493150681257\n",
      "\n",
      "Epoch  3, Batch 0: 0.493150681257 \n",
      "\n",
      "Training Loss: 1.05981993675\n",
      "Validation Loss: 1.06572973728\n",
      "Accuracy (validation): 0.561643838882\n",
      "\n",
      "Epoch  4, Batch 0: 0.561643838882 \n",
      "\n",
      "Training Loss: 1.06206059456\n",
      "Validation Loss: 1.06572771072\n",
      "Accuracy (validation): 0.561643838882\n",
      "\n",
      "Epoch  5, Batch 0: 0.561643838882 \n"
     ]
    }
   ],
   "source": [
    "batch_i = 0\n",
    "\n",
    "print('Checking the Training on a Single Batch, i.e. number {}'.format(batch_i))\n",
    "\n",
    "accuracy_list = []\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        for batch_inputarrays, batch_labels in zip(batch_list(load_training_data(batch_i), size_of_minibatch),\n",
    "                                                   batch_list(load_training_labels(batch_i), size_of_minibatch)):\n",
    "            sess.run(optimizer, feed_dict={x: batch_inputarrays, y: batch_labels, keep_prob: keep_probability})\n",
    "        (training_cost_value, \n",
    "         validation_cost_value, \n",
    "         accuracy_value) = get_stats(sess, batch_inputarrays, batch_labels, cost, accuracy, \n",
    "                                     printout=True)\n",
    "        print('\\nEpoch {:>2}, Batch {}: {} '.format(epoch + 1, batch_i, accuracy_value))\n",
    "        training_losses.append(training_cost_value)\n",
    "        validation_losses.append(validation_cost_value)\n",
    "        accuracy_list.append(accuracy_value)\n",
    "    \n",
    "    # Save the model\n",
    "    #saver = tf.train.Saver()\n",
    "    #save_path = saver.save(sess, \"./trained_model\", global_step=epoch)\n",
    "        \n",
    "plt.plot(accuracy_list)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(training_losses)\n",
    "plt.plot(validation_losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "Training Loss: 1.02988100052\n",
      "Validation Loss: 1.04547405243\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch  1, Batch 0: 0.561643838882\n",
      "\n",
      "Training Loss: 0.885390102863\n",
      "Validation Loss: 1.00900661945\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  1, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00361573696\n",
      "Validation Loss: 1.02351868153\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  1, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10236465931\n",
      "Validation Loss: 1.08400583267\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch  1, Batch 3: 0.547945201397\n",
      "\n",
      "Training Loss: 1.09512507915\n",
      "Validation Loss: 1.09963619709\n",
      "Accuracy (validation): 0.356164395809\n",
      "Epoch  1, Batch 4: 0.356164395809\n",
      "\n",
      "Training Loss: 1.09866631031\n",
      "Validation Loss: 1.1007232666\n",
      "Accuracy (validation): 0.356164395809\n",
      "Epoch  1, Batch 5: 0.356164395809\n",
      "\n",
      "Training Loss: 1.09679329395\n",
      "Validation Loss: 1.09740304947\n",
      "Accuracy (validation): 0.438356161118\n",
      "Epoch  1, Batch 6: 0.438356161118\n",
      "\n",
      "Training Loss: 1.09439110756\n",
      "Validation Loss: 1.09475255013\n",
      "Accuracy (validation): 0.50684928894\n",
      "Epoch  1, Batch 7: 0.50684928894\n",
      "\n",
      "Training Loss: 1.09491872787\n",
      "Validation Loss: 1.09293329716\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch  1, Batch 8: 0.547945201397\n",
      "\n",
      "Training Loss: 1.09183216095\n",
      "Validation Loss: 1.09128832817\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  1, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0897051096\n",
      "Validation Loss: 1.09027659893\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  1, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.08625912666\n",
      "Validation Loss: 1.08913552761\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch  2, Batch 0: 0.547945201397\n",
      "\n",
      "Training Loss: 1.08413672447\n",
      "Validation Loss: 1.08687663078\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch  2, Batch 1: 0.561643838882\n",
      "\n",
      "Training Loss: 1.08381199837\n",
      "Validation Loss: 1.08464968204\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch  2, Batch 2: 0.561643838882\n",
      "\n",
      "Training Loss: 1.09840524197\n",
      "Validation Loss: 1.08363974094\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch  2, Batch 3: 0.561643838882\n",
      "\n",
      "Training Loss: 1.08493065834\n",
      "Validation Loss: 1.08295071125\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch  2, Batch 4: 0.561643838882\n",
      "\n",
      "Training Loss: 1.08094286919\n",
      "Validation Loss: 1.08148133755\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  2, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.08302879333\n",
      "Validation Loss: 1.07829833031\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  2, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.08001375198\n",
      "Validation Loss: 1.07693064213\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  2, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.07840657234\n",
      "Validation Loss: 1.07585096359\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  2, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.07901334763\n",
      "Validation Loss: 1.07456541061\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  2, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.07460331917\n",
      "Validation Loss: 1.0729919672\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  2, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.07100760937\n",
      "Validation Loss: 1.07118439674\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  3, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05950653553\n",
      "Validation Loss: 1.06874454021\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  3, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06519496441\n",
      "Validation Loss: 1.06527543068\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  3, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10106611252\n",
      "Validation Loss: 1.06619131565\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  3, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06887352467\n",
      "Validation Loss: 1.06701028347\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  3, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06790995598\n",
      "Validation Loss: 1.06862068176\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  3, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.07281923294\n",
      "Validation Loss: 1.06914329529\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  3, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0701687336\n",
      "Validation Loss: 1.06819963455\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  3, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.07185399532\n",
      "Validation Loss: 1.06796681881\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  3, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.07244992256\n",
      "Validation Loss: 1.06685912609\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  3, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06677830219\n",
      "Validation Loss: 1.06531906128\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  3, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06299543381\n",
      "Validation Loss: 1.06413173676\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  4, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04819393158\n",
      "Validation Loss: 1.06111764908\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  4, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05545282364\n",
      "Validation Loss: 1.05681943893\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  4, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10295343399\n",
      "Validation Loss: 1.05677056313\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  4, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05949378014\n",
      "Validation Loss: 1.05853998661\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  4, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06244492531\n",
      "Validation Loss: 1.05945396423\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  4, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06395947933\n",
      "Validation Loss: 1.06008994579\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  4, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06280505657\n",
      "Validation Loss: 1.06150519848\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  4, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06514716148\n",
      "Validation Loss: 1.0623666048\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  4, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06825149059\n",
      "Validation Loss: 1.0623383522\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  4, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06520867348\n",
      "Validation Loss: 1.06206893921\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  4, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06009364128\n",
      "Validation Loss: 1.06153476238\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  5, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04705309868\n",
      "Validation Loss: 1.0608509779\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  5, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05842757225\n",
      "Validation Loss: 1.05996274948\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  5, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.09918117523\n",
      "Validation Loss: 1.05999016762\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  5, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06024551392\n",
      "Validation Loss: 1.05895853043\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  5, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06020736694\n",
      "Validation Loss: 1.05749547482\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  5, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06004834175\n",
      "Validation Loss: 1.05597233772\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  5, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0568395853\n",
      "Validation Loss: 1.05525660515\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  5, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05837345123\n",
      "Validation Loss: 1.05468940735\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  5, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06297087669\n",
      "Validation Loss: 1.054682374\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  5, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06056833267\n",
      "Validation Loss: 1.05518090725\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  5, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05249238014\n",
      "Validation Loss: 1.05559766293\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  6, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03851771355\n",
      "Validation Loss: 1.05535042286\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  6, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05215096474\n",
      "Validation Loss: 1.05455577374\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  6, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10131072998\n",
      "Validation Loss: 1.05459296703\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  6, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05683505535\n",
      "Validation Loss: 1.05473423004\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  6, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05996096134\n",
      "Validation Loss: 1.05452597141\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  6, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05943655968\n",
      "Validation Loss: 1.05421793461\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  6, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05619883537\n",
      "Validation Loss: 1.054017663\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  6, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05783557892\n",
      "Validation Loss: 1.05375576019\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  6, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06217169762\n",
      "Validation Loss: 1.0533810854\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  6, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0593996048\n",
      "Validation Loss: 1.05295038223\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  6, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04990100861\n",
      "Validation Loss: 1.05222082138\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  7, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03482484818\n",
      "Validation Loss: 1.05092835426\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  7, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.049680233\n",
      "Validation Loss: 1.04951500893\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  7, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10187745094\n",
      "Validation Loss: 1.04934561253\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  7, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05264246464\n",
      "Validation Loss: 1.04918515682\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  7, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05550038815\n",
      "Validation Loss: 1.04877090454\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  7, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05437302589\n",
      "Validation Loss: 1.04819083214\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  7, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05175948143\n",
      "Validation Loss: 1.047940135\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  7, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05369186401\n",
      "Validation Loss: 1.04761075974\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  7, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05679941177\n",
      "Validation Loss: 1.04770493507\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  7, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05344367027\n",
      "Validation Loss: 1.04758584499\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  7, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04367899895\n",
      "Validation Loss: 1.04723310471\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  8, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0224750042\n",
      "Validation Loss: 1.04527974129\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  8, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0325524807\n",
      "Validation Loss: 1.03725302219\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  8, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10687625408\n",
      "Validation Loss: 1.03598606586\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  8, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03115224838\n",
      "Validation Loss: 1.03412783146\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  8, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02610695362\n",
      "Validation Loss: 1.0296446085\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  8, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03143417835\n",
      "Validation Loss: 1.02826547623\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  8, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0341078043\n",
      "Validation Loss: 1.04165077209\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  8, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04686617851\n",
      "Validation Loss: 1.04257774353\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  8, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05209743977\n",
      "Validation Loss: 1.04225873947\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  8, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04932296276\n",
      "Validation Loss: 1.04177629948\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  8, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.039270401\n",
      "Validation Loss: 1.04110407829\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  9, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01855945587\n",
      "Validation Loss: 1.04007208347\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  9, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03589391708\n",
      "Validation Loss: 1.03954446316\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  9, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10355210304\n",
      "Validation Loss: 1.03918647766\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  9, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04114067554\n",
      "Validation Loss: 1.03969633579\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  9, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04296851158\n",
      "Validation Loss: 1.04017674923\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  9, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04882776737\n",
      "Validation Loss: 1.04067850113\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  9, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04297792912\n",
      "Validation Loss: 1.04093682766\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  9, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04497408867\n",
      "Validation Loss: 1.04088711739\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  9, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.05075502396\n",
      "Validation Loss: 1.04082965851\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  9, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04559540749\n",
      "Validation Loss: 1.04039752483\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch  9, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03707885742\n",
      "Validation Loss: 1.03981184959\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 10, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01426076889\n",
      "Validation Loss: 1.03840088844\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 10, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03175079823\n",
      "Validation Loss: 1.0354809761\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 10, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10645020008\n",
      "Validation Loss: 1.03561234474\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 10, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03668236732\n",
      "Validation Loss: 1.03583788872\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 10, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0345697403\n",
      "Validation Loss: 1.03466963768\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 10, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04056048393\n",
      "Validation Loss: 1.03248524666\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 10, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02751195431\n",
      "Validation Loss: 1.03131353855\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 10, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03476643562\n",
      "Validation Loss: 1.03155052662\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 10, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04243826866\n",
      "Validation Loss: 1.03166127205\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 10, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04062473774\n",
      "Validation Loss: 1.03167498112\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 10, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02528262138\n",
      "Validation Loss: 1.03119838238\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 11, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.998474299908\n",
      "Validation Loss: 1.02942287922\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 11, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02150726318\n",
      "Validation Loss: 1.02769231796\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 11, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10898351669\n",
      "Validation Loss: 1.02727413177\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 11, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02750766277\n",
      "Validation Loss: 1.02656781673\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 11, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02466201782\n",
      "Validation Loss: 1.02626621723\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 11, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03535890579\n",
      "Validation Loss: 1.02587509155\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 11, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01938581467\n",
      "Validation Loss: 1.02592110634\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 11, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03233063221\n",
      "Validation Loss: 1.02701568604\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 11, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03886651993\n",
      "Validation Loss: 1.02793669701\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 11, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03879547119\n",
      "Validation Loss: 1.02887833118\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 11, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02378773689\n",
      "Validation Loss: 1.02906310558\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 12, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.999242961407\n",
      "Validation Loss: 1.02805101871\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 12, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02261352539\n",
      "Validation Loss: 1.02723741531\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 12, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10673379898\n",
      "Validation Loss: 1.02747964859\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 12, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03189003468\n",
      "Validation Loss: 1.02826702595\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 12, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03371238708\n",
      "Validation Loss: 1.02844548225\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 12, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03790092468\n",
      "Validation Loss: 1.02849245071\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 12, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02925789356\n",
      "Validation Loss: 1.02871286869\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 12, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03611660004\n",
      "Validation Loss: 1.02881789207\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 12, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04085850716\n",
      "Validation Loss: 1.02849507332\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 12, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04016900063\n",
      "Validation Loss: 1.02820014954\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 12, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02495598793\n",
      "Validation Loss: 1.02761161327\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 13, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.999050378799\n",
      "Validation Loss: 1.02584958076\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 13, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01988530159\n",
      "Validation Loss: 1.02368986607\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 13, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10738658905\n",
      "Validation Loss: 1.02570521832\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 13, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0309625864\n",
      "Validation Loss: 1.02668714523\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 13, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03359472752\n",
      "Validation Loss: 1.02678310871\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 13, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03680288792\n",
      "Validation Loss: 1.02668917179\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 13, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02963805199\n",
      "Validation Loss: 1.02635252476\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 13, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03285837173\n",
      "Validation Loss: 1.025370121\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 13, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03883981705\n",
      "Validation Loss: 1.02451264858\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 13, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03540289402\n",
      "Validation Loss: 1.02349472046\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 13, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01991117001\n",
      "Validation Loss: 1.02235198021\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 14, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.990950942039\n",
      "Validation Loss: 1.02100551128\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 14, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0163269043\n",
      "Validation Loss: 1.019302845\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 14, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10973536968\n",
      "Validation Loss: 1.01848232746\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 14, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02294385433\n",
      "Validation Loss: 1.0189332962\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 14, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02473807335\n",
      "Validation Loss: 1.01960349083\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 14, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03025841713\n",
      "Validation Loss: 1.01953077316\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 14, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01896882057\n",
      "Validation Loss: 1.01920855045\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 14, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02558398247\n",
      "Validation Loss: 1.01861953735\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 14, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03180861473\n",
      "Validation Loss: 1.01785778999\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 14, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03059732914\n",
      "Validation Loss: 1.01692688465\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 14, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01234674454\n",
      "Validation Loss: 1.01675522327\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 15, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.985312819481\n",
      "Validation Loss: 1.01583147049\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 15, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00996053219\n",
      "Validation Loss: 1.01442933083\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 15, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10743117332\n",
      "Validation Loss: 1.01514029503\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 15, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02149391174\n",
      "Validation Loss: 1.01712810993\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 15, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02429032326\n",
      "Validation Loss: 1.01844668388\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 15, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03165173531\n",
      "Validation Loss: 1.01931762695\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 15, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01954126358\n",
      "Validation Loss: 1.01966631413\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 15, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02741038799\n",
      "Validation Loss: 1.01963186264\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 15, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03567421436\n",
      "Validation Loss: 1.01944673061\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 15, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0321264267\n",
      "Validation Loss: 1.0193104744\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 15, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01536893845\n",
      "Validation Loss: 1.01907491684\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 16, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.988217711449\n",
      "Validation Loss: 1.01872646809\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 16, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01493215561\n",
      "Validation Loss: 1.01836168766\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 16, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.11194598675\n",
      "Validation Loss: 1.01796174049\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 16, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02067279816\n",
      "Validation Loss: 1.01725876331\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 16, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01650905609\n",
      "Validation Loss: 1.01461005211\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 16, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02052438259\n",
      "Validation Loss: 1.01052963734\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 16, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01047134399\n",
      "Validation Loss: 1.01188707352\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 16, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02320957184\n",
      "Validation Loss: 1.01406145096\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 16, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03297626972\n",
      "Validation Loss: 1.01677751541\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 16, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03097522259\n",
      "Validation Loss: 1.01713514328\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 16, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01135718822\n",
      "Validation Loss: 1.01696431637\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 17, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.983145952225\n",
      "Validation Loss: 1.016258955\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 17, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01284575462\n",
      "Validation Loss: 1.01555883884\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 17, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.11140501499\n",
      "Validation Loss: 1.01502716541\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 17, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01955032349\n",
      "Validation Loss: 1.01428031921\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 17, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01964962482\n",
      "Validation Loss: 1.0136910677\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 17, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02535510063\n",
      "Validation Loss: 1.01340985298\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 17, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01365506649\n",
      "Validation Loss: 1.01318669319\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 17, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02112460136\n",
      "Validation Loss: 1.01265764236\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 17, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02788436413\n",
      "Validation Loss: 1.01189875603\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 17, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02538144588\n",
      "Validation Loss: 1.01101565361\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 17, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00284028053\n",
      "Validation Loss: 1.01008820534\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 18, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.968234717846\n",
      "Validation Loss: 1.00843095779\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 18, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0010882616\n",
      "Validation Loss: 1.00633192062\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 18, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.11992788315\n",
      "Validation Loss: 1.00567722321\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 18, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00964081287\n",
      "Validation Loss: 1.00630176067\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 18, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.008659482\n",
      "Validation Loss: 1.00653481483\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 18, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02000236511\n",
      "Validation Loss: 1.00688946247\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 18, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00807905197\n",
      "Validation Loss: 1.00756788254\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 18, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01859641075\n",
      "Validation Loss: 1.00807631016\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 18, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02535581589\n",
      "Validation Loss: 1.00844788551\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 18, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0240623951\n",
      "Validation Loss: 1.00857377052\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 18, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00427377224\n",
      "Validation Loss: 1.00872576237\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 19, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.97174090147\n",
      "Validation Loss: 1.0085517168\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 19, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00286519527\n",
      "Validation Loss: 1.00845336914\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 19, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.11635947227\n",
      "Validation Loss: 1.00823605061\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 19, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01476275921\n",
      "Validation Loss: 1.00815200806\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 19, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01642537117\n",
      "Validation Loss: 1.00830948353\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 19, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02071809769\n",
      "Validation Loss: 1.00827884674\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 19, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01284456253\n",
      "Validation Loss: 1.00805664062\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 19, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01876485348\n",
      "Validation Loss: 1.00780904293\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 19, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02517914772\n",
      "Validation Loss: 1.00717544556\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 19, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02215337753\n",
      "Validation Loss: 1.00643062592\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 19, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00241696835\n",
      "Validation Loss: 1.00552916527\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 20, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.967343568802\n",
      "Validation Loss: 1.00436162949\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 20, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.999397337437\n",
      "Validation Loss: 1.00275802612\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 20, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.11971700191\n",
      "Validation Loss: 1.00274825096\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 20, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0086979866\n",
      "Validation Loss: 1.00353598595\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 20, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01041769981\n",
      "Validation Loss: 1.00543236732\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 20, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01767587662\n",
      "Validation Loss: 1.00408530235\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 20, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00660705566\n",
      "Validation Loss: 1.00284838676\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 20, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01327753067\n",
      "Validation Loss: 1.00147092342\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 20, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02083826065\n",
      "Validation Loss: 1.00157749653\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 20, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01691007614\n",
      "Validation Loss: 1.00231266022\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 20, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.993519127369\n",
      "Validation Loss: 1.00041913986\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 21, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.955048322678\n",
      "Validation Loss: 0.99860149622\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 21, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.99155241251\n",
      "Validation Loss: 0.996805369854\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 21, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.12395131588\n",
      "Validation Loss: 0.996953964233\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 21, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00280785561\n",
      "Validation Loss: 0.997326910496\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 21, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00167119503\n",
      "Validation Loss: 0.997580349445\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 21, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01256608963\n",
      "Validation Loss: 0.997500479221\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 21, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.998315811157\n",
      "Validation Loss: 0.997472763062\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 21, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01235961914\n",
      "Validation Loss: 0.997751295567\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 21, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01624155045\n",
      "Validation Loss: 0.997782588005\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 21, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01654887199\n",
      "Validation Loss: 0.99762660265\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 21, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.993056952953\n",
      "Validation Loss: 0.997506141663\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 22, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.954273462296\n",
      "Validation Loss: 0.996903717518\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 22, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.990320086479\n",
      "Validation Loss: 0.996012449265\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 22, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.12391161919\n",
      "Validation Loss: 0.996528208256\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 22, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00296497345\n",
      "Validation Loss: 0.997112452984\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 22, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00178408623\n",
      "Validation Loss: 0.997457921505\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 22, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01459896564\n",
      "Validation Loss: 0.997656822205\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 22, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.996537208557\n",
      "Validation Loss: 0.998034775257\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 22, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01258158684\n",
      "Validation Loss: 0.998150646687\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 22, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01550614834\n",
      "Validation Loss: 0.997857093811\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 22, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01315116882\n",
      "Validation Loss: 0.997204601765\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 22, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.993040800095\n",
      "Validation Loss: 0.996689379215\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 23, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.954369068146\n",
      "Validation Loss: 0.996377944946\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 23, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.991042613983\n",
      "Validation Loss: 0.996113598347\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 23, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.12372016907\n",
      "Validation Loss: 0.995688438416\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 23, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.999217391014\n",
      "Validation Loss: 0.994709253311\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 23, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.996680617332\n",
      "Validation Loss: 0.99430167675\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 23, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.011947155\n",
      "Validation Loss: 0.993827402592\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 23, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.988795757294\n",
      "Validation Loss: 0.993125617504\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 23, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00962734222\n",
      "Validation Loss: 0.992051303387\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 23, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01418459415\n",
      "Validation Loss: 0.992162287235\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 23, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.0101685524\n",
      "Validation Loss: 0.992992162704\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 23, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.992600858212\n",
      "Validation Loss: 0.993608057499\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 24, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.953856468201\n",
      "Validation Loss: 0.993954896927\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 24, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.988278508186\n",
      "Validation Loss: 0.993266701698\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 24, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.12200677395\n",
      "Validation Loss: 0.992764174938\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 24, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.995318174362\n",
      "Validation Loss: 0.992806613445\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 24, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.990998089314\n",
      "Validation Loss: 0.992868840694\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 24, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01075530052\n",
      "Validation Loss: 0.992389857769\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 24, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.983169198036\n",
      "Validation Loss: 0.99191981554\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 24, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00860893726\n",
      "Validation Loss: 0.991245090961\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 24, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00643610954\n",
      "Validation Loss: 0.990505576134\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 24, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00939142704\n",
      "Validation Loss: 0.99024772644\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 24, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.983222961426\n",
      "Validation Loss: 0.989784896374\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 25, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.942108213902\n",
      "Validation Loss: 0.988708734512\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 25, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.979157209396\n",
      "Validation Loss: 0.987355172634\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 25, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.12588214874\n",
      "Validation Loss: 0.987187623978\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 25, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.99064540863\n",
      "Validation Loss: 0.987348377705\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 25, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.985629320145\n",
      "Validation Loss: 0.987342596054\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 25, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00557994843\n",
      "Validation Loss: 0.987239480019\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 25, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.981291592121\n",
      "Validation Loss: 0.987212717533\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 25, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00574994087\n",
      "Validation Loss: 0.987215638161\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 25, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00485062599\n",
      "Validation Loss: 0.987183272839\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 25, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00900387764\n",
      "Validation Loss: 0.987266540527\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 25, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.983946621418\n",
      "Validation Loss: 0.987548410892\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 26, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.941296875477\n",
      "Validation Loss: 0.986966907978\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 26, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.98015409708\n",
      "Validation Loss: 0.986026406288\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 26, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.12514257431\n",
      "Validation Loss: 0.985564887524\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 26, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.987489104271\n",
      "Validation Loss: 0.984892129898\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 26, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.980401337147\n",
      "Validation Loss: 0.98377519846\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 26, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00268816948\n",
      "Validation Loss: 0.982289433479\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 26, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.965058863163\n",
      "Validation Loss: 0.981438934803\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 26, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00307369232\n",
      "Validation Loss: 0.981170773506\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 26, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 0.998739182949\n",
      "Validation Loss: 0.981033980846\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 26, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.999933123589\n",
      "Validation Loss: 0.980391204357\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 26, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.974094092846\n",
      "Validation Loss: 0.980013787746\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 27, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.929636359215\n",
      "Validation Loss: 0.979555726051\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 27, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.970450043678\n",
      "Validation Loss: 0.979265511036\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 27, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.12693011761\n",
      "Validation Loss: 0.976237893105\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 27, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.984894514084\n",
      "Validation Loss: 0.976315736771\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 27, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.988665997982\n",
      "Validation Loss: 0.978899300098\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 27, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 0.996921420097\n",
      "Validation Loss: 0.980726480484\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 27, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.992551803589\n",
      "Validation Loss: 0.981435477734\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 27, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00317645073\n",
      "Validation Loss: 0.981025278568\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 27, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01137781143\n",
      "Validation Loss: 0.980050384998\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 27, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.999713122845\n",
      "Validation Loss: 0.978569746017\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 27, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.97831851244\n",
      "Validation Loss: 0.976703882217\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 28, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.932260036469\n",
      "Validation Loss: 0.974006533623\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 28, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.9705286026\n",
      "Validation Loss: 0.97275608778\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 28, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.12461769581\n",
      "Validation Loss: 0.975055336952\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 28, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.981683850288\n",
      "Validation Loss: 0.976227343082\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 28, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.978886246681\n",
      "Validation Loss: 0.976592719555\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 28, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 0.996094346046\n",
      "Validation Loss: 0.976121485233\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 28, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.976108193398\n",
      "Validation Loss: 0.97551202774\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 28, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00223374367\n",
      "Validation Loss: 0.975383281708\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 28, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00398266315\n",
      "Validation Loss: 0.97517490387\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 28, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.996400237083\n",
      "Validation Loss: 0.975785017014\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 28, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.97717320919\n",
      "Validation Loss: 0.976234138012\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 29, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.930340528488\n",
      "Validation Loss: 0.974245071411\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 29, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.960765302181\n",
      "Validation Loss: 0.962316215038\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 29, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.1129270792\n",
      "Validation Loss: 0.962505698204\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 29, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.972089886665\n",
      "Validation Loss: 0.969691216946\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 29, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.983342170715\n",
      "Validation Loss: 0.978394687176\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 29, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 0.995559573174\n",
      "Validation Loss: 0.979404091835\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 29, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.979563891888\n",
      "Validation Loss: 0.978764891624\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 29, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 0.999674916267\n",
      "Validation Loss: 0.977954685688\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 29, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00559735298\n",
      "Validation Loss: 0.977019131184\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 29, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.995291292667\n",
      "Validation Loss: 0.976576387882\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 29, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.973787546158\n",
      "Validation Loss: 0.976230800152\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 30, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.932160675526\n",
      "Validation Loss: 0.975235819817\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 30, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.971579730511\n",
      "Validation Loss: 0.973601460457\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 30, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.10091280937\n",
      "Validation Loss: 0.972681879997\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 30, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.978861451149\n",
      "Validation Loss: 0.97229295969\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 30, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.979633569717\n",
      "Validation Loss: 0.970745682716\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 30, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 0.987871408463\n",
      "Validation Loss: 0.970154762268\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 30, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.968330442905\n",
      "Validation Loss: 0.96925753355\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 30, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 0.992203891277\n",
      "Validation Loss: 0.96860575676\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 30, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00093865395\n",
      "Validation Loss: 0.967881500721\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 30, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.985744833946\n",
      "Validation Loss: 0.967039346695\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 30, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.958546936512\n",
      "Validation Loss: 0.965845584869\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 31, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.925935268402\n",
      "Validation Loss: 0.963545799255\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 31, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.960466861725\n",
      "Validation Loss: 0.962772130966\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 31, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.08066105843\n",
      "Validation Loss: 0.963682949543\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 31, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.965041995049\n",
      "Validation Loss: 0.963440775871\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 31, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.96342587471\n",
      "Validation Loss: 0.962529838085\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 31, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 0.980980932713\n",
      "Validation Loss: 0.96220010519\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 31, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.952118337154\n",
      "Validation Loss: 0.962185680866\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 31, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 0.989037871361\n",
      "Validation Loss: 0.96091657877\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 31, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 1.00064516068\n",
      "Validation Loss: 0.95750105381\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 31, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.975255489349\n",
      "Validation Loss: 0.954172432423\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 31, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.940870761871\n",
      "Validation Loss: 0.951974093914\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 32, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.914082705975\n",
      "Validation Loss: 0.950890302658\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 32, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.957146883011\n",
      "Validation Loss: 0.95095717907\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 32, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06846797466\n",
      "Validation Loss: 0.951876997948\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 32, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.970584392548\n",
      "Validation Loss: 0.951111257076\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 32, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.983334302902\n",
      "Validation Loss: 0.95103263855\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 32, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 0.97298759222\n",
      "Validation Loss: 0.951997339725\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 32, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.955711424351\n",
      "Validation Loss: 0.953315615654\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 32, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 0.992394447327\n",
      "Validation Loss: 0.955089628696\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 32, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 0.995226383209\n",
      "Validation Loss: 0.956511378288\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 32, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.980573832989\n",
      "Validation Loss: 0.956470310688\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 32, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.954511523247\n",
      "Validation Loss: 0.955724239349\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 33, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.919194936752\n",
      "Validation Loss: 0.953508138657\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 33, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.959815502167\n",
      "Validation Loss: 0.949681758881\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 33, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.06819045544\n",
      "Validation Loss: 0.946622848511\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 33, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.952045321465\n",
      "Validation Loss: 0.941618800163\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 33, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.970140337944\n",
      "Validation Loss: 0.936577498913\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 33, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 0.966705083847\n",
      "Validation Loss: 0.932944595814\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 33, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.940271735191\n",
      "Validation Loss: 0.933384418488\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 33, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 0.972563266754\n",
      "Validation Loss: 0.933667421341\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 33, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 0.988310694695\n",
      "Validation Loss: 0.935716092587\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 33, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.961403489113\n",
      "Validation Loss: 0.937781870365\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 33, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.926579236984\n",
      "Validation Loss: 0.938582003117\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 34, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.891745567322\n",
      "Validation Loss: 0.935566842556\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 34, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.935337126255\n",
      "Validation Loss: 0.931517899036\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 34, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.04023659229\n",
      "Validation Loss: 0.92914390564\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 34, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.938289582729\n",
      "Validation Loss: 0.930253148079\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 34, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.967423498631\n",
      "Validation Loss: 0.933253645897\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 34, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 0.951715648174\n",
      "Validation Loss: 0.934534490108\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 34, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.930170238018\n",
      "Validation Loss: 0.935896039009\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 34, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 0.977773785591\n",
      "Validation Loss: 0.935967743397\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 34, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 0.980308294296\n",
      "Validation Loss: 0.935076236725\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 34, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.956134855747\n",
      "Validation Loss: 0.934223115444\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 34, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.915563285351\n",
      "Validation Loss: 0.932367742062\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 35, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.889276385307\n",
      "Validation Loss: 0.929318249226\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 35, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.941994547844\n",
      "Validation Loss: 0.927164137363\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 35, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.02029156685\n",
      "Validation Loss: 0.927714943886\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 35, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.941616594791\n",
      "Validation Loss: 0.929066359997\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 35, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.949422359467\n",
      "Validation Loss: 0.92741048336\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 35, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 0.943517029285\n",
      "Validation Loss: 0.925271570683\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 35, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.917781710625\n",
      "Validation Loss: 0.926482439041\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 35, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 0.972258687019\n",
      "Validation Loss: 0.927819252014\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 35, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 0.972978830338\n",
      "Validation Loss: 0.927902877331\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 35, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.956189393997\n",
      "Validation Loss: 0.926604986191\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 35, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.908794760704\n",
      "Validation Loss: 0.926026463509\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 36, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.889452815056\n",
      "Validation Loss: 0.924540281296\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 36, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.94249767065\n",
      "Validation Loss: 0.922847270966\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 36, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.03091561794\n",
      "Validation Loss: 0.921959221363\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 36, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.93254673481\n",
      "Validation Loss: 0.921103477478\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 36, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.939276635647\n",
      "Validation Loss: 0.91947966814\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 36, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 0.944668531418\n",
      "Validation Loss: 0.91836309433\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 36, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.912454485893\n",
      "Validation Loss: 0.917413592339\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 36, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 0.962374210358\n",
      "Validation Loss: 0.91361027956\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 36, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 0.972802400589\n",
      "Validation Loss: 0.910586297512\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 36, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.94225859642\n",
      "Validation Loss: 0.909514307976\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 36, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.892934322357\n",
      "Validation Loss: 0.910159051418\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 37, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.874737143517\n",
      "Validation Loss: 0.910383224487\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 37, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.919000387192\n",
      "Validation Loss: 0.90692538023\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 37, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 1.01457512379\n",
      "Validation Loss: 0.909213006496\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 37, Batch 3: 0.561643838882\n",
      "\n",
      "Training Loss: 0.936007499695\n",
      "Validation Loss: 0.915381669998\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 37, Batch 4: 0.561643838882\n",
      "\n",
      "Training Loss: 0.938678383827\n",
      "Validation Loss: 0.916785061359\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 37, Batch 5: 0.561643838882\n",
      "\n",
      "Training Loss: 0.941124677658\n",
      "Validation Loss: 0.920315802097\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 37, Batch 6: 0.561643838882\n",
      "\n",
      "Training Loss: 0.927378892899\n",
      "Validation Loss: 0.928857564926\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 37, Batch 7: 0.561643838882\n",
      "\n",
      "Training Loss: 0.977341651917\n",
      "Validation Loss: 0.931081712246\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 37, Batch 8: 0.561643838882\n",
      "\n",
      "Training Loss: 0.978999257088\n",
      "Validation Loss: 0.931483626366\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 37, Batch 9: 0.561643838882\n",
      "\n",
      "Training Loss: 0.939744710922\n",
      "Validation Loss: 0.929878532887\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 37, Batch 10: 0.561643838882\n",
      "\n",
      "Training Loss: 0.907715380192\n",
      "Validation Loss: 0.928506851196\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 38, Batch 0: 0.561643838882\n",
      "\n",
      "Training Loss: 0.892241835594\n",
      "Validation Loss: 0.92741382122\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 38, Batch 1: 0.561643838882\n",
      "\n",
      "Training Loss: 0.930241525173\n",
      "Validation Loss: 0.926846325397\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 38, Batch 2: 0.561643838882\n",
      "\n",
      "Training Loss: 1.02626597881\n",
      "Validation Loss: 0.925738632679\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 38, Batch 3: 0.561643838882\n",
      "\n",
      "Training Loss: 0.925965666771\n",
      "Validation Loss: 0.924983382225\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 38, Batch 4: 0.561643838882\n",
      "\n",
      "Training Loss: 0.932855367661\n",
      "Validation Loss: 0.923821747303\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 38, Batch 5: 0.561643838882\n",
      "\n",
      "Training Loss: 0.93514084816\n",
      "Validation Loss: 0.92345315218\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 38, Batch 6: 0.561643838882\n",
      "\n",
      "Training Loss: 0.914121031761\n",
      "Validation Loss: 0.923294305801\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 38, Batch 7: 0.561643838882\n",
      "\n",
      "Training Loss: 0.96814930439\n",
      "Validation Loss: 0.922199726105\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 38, Batch 8: 0.561643838882\n",
      "\n",
      "Training Loss: 0.97455728054\n",
      "Validation Loss: 0.919817268848\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 38, Batch 9: 0.561643838882\n",
      "\n",
      "Training Loss: 0.926443457603\n",
      "Validation Loss: 0.91645604372\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 38, Batch 10: 0.561643838882\n",
      "\n",
      "Training Loss: 0.889663338661\n",
      "Validation Loss: 0.915116071701\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 39, Batch 0: 0.561643838882\n",
      "\n",
      "Training Loss: 0.875947833061\n",
      "Validation Loss: 0.913411796093\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 39, Batch 1: 0.561643838882\n",
      "\n",
      "Training Loss: 0.91273522377\n",
      "Validation Loss: 0.911037504673\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 39, Batch 2: 0.561643838882\n",
      "\n",
      "Training Loss: 0.997864484787\n",
      "Validation Loss: 0.910282492638\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 39, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.907736420631\n",
      "Validation Loss: 0.911098003387\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 39, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.92382478714\n",
      "Validation Loss: 0.910176336765\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 39, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 0.918658137321\n",
      "Validation Loss: 0.908025681973\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 39, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.905803203583\n",
      "Validation Loss: 0.908655047417\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 39, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 0.96372961998\n",
      "Validation Loss: 0.90952026844\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 39, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 0.97503554821\n",
      "Validation Loss: 0.909203708172\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 39, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.924996376038\n",
      "Validation Loss: 0.909270405769\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 39, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.881265878677\n",
      "Validation Loss: 0.909471571445\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 40, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.870971560478\n",
      "Validation Loss: 0.909288048744\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 40, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.901462674141\n",
      "Validation Loss: 0.909246981144\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 40, Batch 2: 0.561643838882\n",
      "\n",
      "Training Loss: 1.00372362137\n",
      "Validation Loss: 0.909117519855\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 40, Batch 3: 0.561643838882\n",
      "\n",
      "Training Loss: 0.900521159172\n",
      "Validation Loss: 0.908399164677\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 40, Batch 4: 0.547945201397\n",
      "\n",
      "Training Loss: 0.902460038662\n",
      "Validation Loss: 0.907463490963\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 40, Batch 5: 0.547945201397\n",
      "\n",
      "Training Loss: 0.905440092087\n",
      "Validation Loss: 0.906326174736\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 40, Batch 6: 0.561643838882\n",
      "\n",
      "Training Loss: 0.888833940029\n",
      "Validation Loss: 0.904790043831\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 40, Batch 7: 0.547945201397\n",
      "\n",
      "Training Loss: 0.940579295158\n",
      "Validation Loss: 0.903142929077\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 40, Batch 8: 0.561643838882\n",
      "\n",
      "Training Loss: 0.966956019402\n",
      "Validation Loss: 0.905318260193\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 40, Batch 9: 0.547945201397\n",
      "\n",
      "Training Loss: 0.919257283211\n",
      "Validation Loss: 0.909827888012\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 40, Batch 10: 0.561643838882\n",
      "\n",
      "Training Loss: 0.875265002251\n",
      "Validation Loss: 0.910822212696\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 41, Batch 0: 0.561643838882\n",
      "\n",
      "Training Loss: 0.859835445881\n",
      "Validation Loss: 0.909201920033\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 41, Batch 1: 0.561643838882\n",
      "\n",
      "Training Loss: 0.896246254444\n",
      "Validation Loss: 0.904314219952\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 41, Batch 2: 0.561643838882\n",
      "\n",
      "Training Loss: 0.988463044167\n",
      "Validation Loss: 0.903394937515\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 41, Batch 3: 0.561643838882\n",
      "\n",
      "Training Loss: 0.906778991222\n",
      "Validation Loss: 0.905228078365\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 41, Batch 4: 0.561643838882\n",
      "\n",
      "Training Loss: 0.9057751894\n",
      "Validation Loss: 0.906397879124\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 41, Batch 5: 0.561643838882\n",
      "\n",
      "Training Loss: 0.911188960075\n",
      "Validation Loss: 0.906910717487\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 41, Batch 6: 0.561643838882\n",
      "\n",
      "Training Loss: 0.898493230343\n",
      "Validation Loss: 0.909583926201\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 41, Batch 7: 0.561643838882\n",
      "\n",
      "Training Loss: 0.943698167801\n",
      "Validation Loss: 0.911401093006\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 41, Batch 8: 0.561643838882\n",
      "\n",
      "Training Loss: 0.960906088352\n",
      "Validation Loss: 0.913037121296\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 41, Batch 9: 0.561643838882\n",
      "\n",
      "Training Loss: 0.923189640045\n",
      "Validation Loss: 0.915844023228\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 41, Batch 10: 0.561643838882\n",
      "\n",
      "Training Loss: 0.876111447811\n",
      "Validation Loss: 0.915913105011\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 42, Batch 0: 0.561643838882\n",
      "\n",
      "Training Loss: 0.864919304848\n",
      "Validation Loss: 0.913604080677\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 42, Batch 1: 0.561643838882\n",
      "\n",
      "Training Loss: 0.903647243977\n",
      "Validation Loss: 0.908435344696\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 42, Batch 2: 0.561643838882\n",
      "\n",
      "Training Loss: 0.988466918468\n",
      "Validation Loss: 0.906280517578\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 42, Batch 3: 0.561643838882\n",
      "\n",
      "Training Loss: 0.904953896999\n",
      "Validation Loss: 0.906142234802\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 42, Batch 4: 0.561643838882\n",
      "\n",
      "Training Loss: 0.898357331753\n",
      "Validation Loss: 0.905006289482\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 42, Batch 5: 0.561643838882\n",
      "\n",
      "Training Loss: 0.895211160183\n",
      "Validation Loss: 0.904293298721\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 42, Batch 6: 0.547945201397\n",
      "\n",
      "Training Loss: 0.885485172272\n",
      "Validation Loss: 0.903006017208\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 42, Batch 7: 0.561643838882\n",
      "\n",
      "Training Loss: 0.935583353043\n",
      "Validation Loss: 0.901636600494\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 42, Batch 8: 0.561643838882\n",
      "\n",
      "Training Loss: 0.964513659477\n",
      "Validation Loss: 0.902272880077\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 42, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.889108479023\n",
      "Validation Loss: 0.902716517448\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 42, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.861184298992\n",
      "Validation Loss: 0.899233162403\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 43, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.837000966072\n",
      "Validation Loss: 0.896136045456\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 43, Batch 1: 0.561643838882\n",
      "\n",
      "Training Loss: 0.875095903873\n",
      "Validation Loss: 0.891968011856\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 43, Batch 2: 0.561643838882\n",
      "\n",
      "Training Loss: 0.97650384903\n",
      "Validation Loss: 0.89293462038\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 43, Batch 3: 0.547945201397\n",
      "\n",
      "Training Loss: 0.898054182529\n",
      "Validation Loss: 0.89862716198\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 43, Batch 4: 0.561643838882\n",
      "\n",
      "Training Loss: 0.892686903477\n",
      "Validation Loss: 0.902558863163\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 43, Batch 5: 0.561643838882\n",
      "\n",
      "Training Loss: 0.901135981083\n",
      "Validation Loss: 0.904793441296\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 43, Batch 6: 0.561643838882\n",
      "\n",
      "Training Loss: 0.88936316967\n",
      "Validation Loss: 0.906150698662\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 43, Batch 7: 0.561643838882\n",
      "\n",
      "Training Loss: 0.943015575409\n",
      "Validation Loss: 0.906227111816\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 43, Batch 8: 0.561643838882\n",
      "\n",
      "Training Loss: 0.944056332111\n",
      "Validation Loss: 0.908351659775\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 43, Batch 9: 0.561643838882\n",
      "\n",
      "Training Loss: 0.908731460571\n",
      "Validation Loss: 0.911450207233\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 43, Batch 10: 0.561643838882\n",
      "\n",
      "Training Loss: 0.862798511982\n",
      "Validation Loss: 0.910160303116\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 44, Batch 0: 0.561643838882\n",
      "\n",
      "Training Loss: 0.849912166595\n",
      "Validation Loss: 0.906236827374\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 44, Batch 1: 0.561643838882\n",
      "\n",
      "Training Loss: 0.873374402523\n",
      "Validation Loss: 0.899364709854\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 44, Batch 2: 0.547945201397\n",
      "\n",
      "Training Loss: 0.961361944675\n",
      "Validation Loss: 0.891708910465\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 44, Batch 3: 0.547945201397\n",
      "\n",
      "Training Loss: 0.879541099072\n",
      "Validation Loss: 0.889812529087\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 44, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.862318873405\n",
      "Validation Loss: 0.889462828636\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 44, Batch 5: 0.561643838882\n",
      "\n",
      "Training Loss: 0.862638890743\n",
      "Validation Loss: 0.886122941971\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 44, Batch 6: 0.561643838882\n",
      "\n",
      "Training Loss: 0.855593919754\n",
      "Validation Loss: 0.880782842636\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 44, Batch 7: 0.561643838882\n",
      "\n",
      "Training Loss: 0.934640645981\n",
      "Validation Loss: 0.878394663334\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 44, Batch 8: 0.561643838882\n",
      "\n",
      "Training Loss: 0.934202492237\n",
      "Validation Loss: 0.87816119194\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 44, Batch 9: 0.561643838882\n",
      "\n",
      "Training Loss: 0.880754768848\n",
      "Validation Loss: 0.880539476871\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 44, Batch 10: 0.561643838882\n",
      "\n",
      "Training Loss: 0.846093893051\n",
      "Validation Loss: 0.88320171833\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 45, Batch 0: 0.561643838882\n",
      "\n",
      "Training Loss: 0.833262383938\n",
      "Validation Loss: 0.883476555347\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 45, Batch 1: 0.561643838882\n",
      "\n",
      "Training Loss: 0.88164961338\n",
      "Validation Loss: 0.880999624729\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 45, Batch 2: 0.561643838882\n",
      "\n",
      "Training Loss: 0.96939343214\n",
      "Validation Loss: 0.881155788898\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 45, Batch 3: 0.561643838882\n",
      "\n",
      "Training Loss: 0.88912075758\n",
      "Validation Loss: 0.883432805538\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 45, Batch 4: 0.561643838882\n",
      "\n",
      "Training Loss: 0.880395054817\n",
      "Validation Loss: 0.881022512913\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 45, Batch 5: 0.561643838882\n",
      "\n",
      "Training Loss: 0.873972415924\n",
      "Validation Loss: 0.877178788185\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 45, Batch 6: 0.561643838882\n",
      "\n",
      "Training Loss: 0.880026340485\n",
      "Validation Loss: 0.87791633606\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 45, Batch 7: 0.561643838882\n",
      "\n",
      "Training Loss: 0.927152514458\n",
      "Validation Loss: 0.878187537193\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 45, Batch 8: 0.547945201397\n",
      "\n",
      "Training Loss: 0.928177833557\n",
      "Validation Loss: 0.885178685188\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 45, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.875020742416\n",
      "Validation Loss: 0.894884943962\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 45, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.84713447094\n",
      "Validation Loss: 0.892929494381\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 46, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.819599866867\n",
      "Validation Loss: 0.884467422962\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 46, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.865362763405\n",
      "Validation Loss: 0.873467504978\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 46, Batch 2: 0.561643838882\n",
      "\n",
      "Training Loss: 0.95562338829\n",
      "Validation Loss: 0.868478238583\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 46, Batch 3: 0.561643838882\n",
      "\n",
      "Training Loss: 0.871026754379\n",
      "Validation Loss: 0.870189428329\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 46, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.856909453869\n",
      "Validation Loss: 0.871146440506\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 46, Batch 5: 0.575342476368\n",
      "\n",
      "Training Loss: 0.861041069031\n",
      "Validation Loss: 0.872137904167\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 46, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.868009924889\n",
      "Validation Loss: 0.874449014664\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 46, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 0.922884106636\n",
      "Validation Loss: 0.873944818974\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 46, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 0.94651389122\n",
      "Validation Loss: 0.873804807663\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 46, Batch 9: 0.561643838882\n",
      "\n",
      "Training Loss: 0.876207888126\n",
      "Validation Loss: 0.876109719276\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 46, Batch 10: 0.547945201397\n",
      "\n",
      "Training Loss: 0.853509426117\n",
      "Validation Loss: 0.876945257187\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 47, Batch 0: 0.547945201397\n",
      "\n",
      "Training Loss: 0.831778347492\n",
      "Validation Loss: 0.875690340996\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 47, Batch 1: 0.547945201397\n",
      "\n",
      "Training Loss: 0.851522088051\n",
      "Validation Loss: 0.870409309864\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 47, Batch 2: 0.561643838882\n",
      "\n",
      "Training Loss: 0.956132948399\n",
      "Validation Loss: 0.869179129601\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 47, Batch 3: 0.561643838882\n",
      "\n",
      "Training Loss: 0.868902921677\n",
      "Validation Loss: 0.872228145599\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 47, Batch 4: 0.561643838882\n",
      "\n",
      "Training Loss: 0.853891909122\n",
      "Validation Loss: 0.869888007641\n",
      "Accuracy (validation): 0.534246563911\n",
      "Epoch 47, Batch 5: 0.534246563911\n",
      "\n",
      "Training Loss: 0.846977233887\n",
      "Validation Loss: 0.866058707237\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 47, Batch 6: 0.547945201397\n",
      "\n",
      "Training Loss: 0.854832053185\n",
      "Validation Loss: 0.867557048798\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 47, Batch 7: 0.561643838882\n",
      "\n",
      "Training Loss: 0.916037321091\n",
      "Validation Loss: 0.869892537594\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 47, Batch 8: 0.547945201397\n",
      "\n",
      "Training Loss: 0.924805402756\n",
      "Validation Loss: 0.873888134956\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 47, Batch 9: 0.547945201397\n",
      "\n",
      "Training Loss: 0.860907435417\n",
      "Validation Loss: 0.8776242733\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 47, Batch 10: 0.561643838882\n",
      "\n",
      "Training Loss: 0.834936201572\n",
      "Validation Loss: 0.882273554802\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 48, Batch 0: 0.561643838882\n",
      "\n",
      "Training Loss: 0.821343839169\n",
      "Validation Loss: 0.886504292488\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 48, Batch 1: 0.561643838882\n",
      "\n",
      "Training Loss: 0.844735264778\n",
      "Validation Loss: 0.883543431759\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 48, Batch 2: 0.561643838882\n",
      "\n",
      "Training Loss: 0.954902887344\n",
      "Validation Loss: 0.879823863506\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 48, Batch 3: 0.561643838882\n",
      "\n",
      "Training Loss: 0.870616734028\n",
      "Validation Loss: 0.876652240753\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 48, Batch 4: 0.561643838882\n",
      "\n",
      "Training Loss: 0.849333882332\n",
      "Validation Loss: 0.871871948242\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 48, Batch 5: 0.561643838882\n",
      "\n",
      "Training Loss: 0.855487465858\n",
      "Validation Loss: 0.870777368546\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 48, Batch 6: 0.547945201397\n",
      "\n",
      "Training Loss: 0.884056031704\n",
      "Validation Loss: 0.872880935669\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 48, Batch 7: 0.561643838882\n",
      "\n",
      "Training Loss: 0.927705347538\n",
      "Validation Loss: 0.871870756149\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 48, Batch 8: 0.561643838882\n",
      "\n",
      "Training Loss: 0.925035536289\n",
      "Validation Loss: 0.870058953762\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 48, Batch 9: 0.547945201397\n",
      "\n",
      "Training Loss: 0.865893661976\n",
      "Validation Loss: 0.868598997593\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 48, Batch 10: 0.547945201397\n",
      "\n",
      "Training Loss: 0.843587756157\n",
      "Validation Loss: 0.867151141167\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 49, Batch 0: 0.547945201397\n",
      "\n",
      "Training Loss: 0.815319120884\n",
      "Validation Loss: 0.86457490921\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 49, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.826581835747\n",
      "Validation Loss: 0.852173268795\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 49, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 0.930457055569\n",
      "Validation Loss: 0.867846369743\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 49, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.890947818756\n",
      "Validation Loss: 0.884246110916\n",
      "Accuracy (validation): 0.589041113853\n",
      "Epoch 49, Batch 4: 0.589041113853\n",
      "\n",
      "Training Loss: 0.87840205431\n",
      "Validation Loss: 0.883668541908\n",
      "Accuracy (validation): 0.589041113853\n",
      "Epoch 49, Batch 5: 0.589041113853\n",
      "\n",
      "Training Loss: 0.849299669266\n",
      "Validation Loss: 0.876176118851\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 49, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.868452191353\n",
      "Validation Loss: 0.875666618347\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 49, Batch 7: 0.575342476368\n",
      "\n",
      "Training Loss: 0.934581875801\n",
      "Validation Loss: 0.880073785782\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 49, Batch 8: 0.561643838882\n",
      "\n",
      "Training Loss: 0.94201695919\n",
      "Validation Loss: 0.882023751736\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 49, Batch 9: 0.561643838882\n",
      "\n",
      "Training Loss: 0.874722540379\n",
      "Validation Loss: 0.880748927593\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 49, Batch 10: 0.575342476368\n",
      "\n",
      "Training Loss: 0.856128692627\n",
      "Validation Loss: 0.878586113453\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 50, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.83238607645\n",
      "Validation Loss: 0.876455724239\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 50, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.851482868195\n",
      "Validation Loss: 0.877217829227\n",
      "Accuracy (validation): 0.589041113853\n",
      "Epoch 50, Batch 2: 0.589041113853\n",
      "\n",
      "Training Loss: 0.935759365559\n",
      "Validation Loss: 0.879881262779\n",
      "Accuracy (validation): 0.589041113853\n",
      "Epoch 50, Batch 3: 0.589041113853\n",
      "\n",
      "Training Loss: 0.87587338686\n",
      "Validation Loss: 0.879663348198\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 50, Batch 4: 0.575342476368\n",
      "\n",
      "Training Loss: 0.860327124596\n",
      "Validation Loss: 0.875143289566\n",
      "Accuracy (validation): 0.589041113853\n",
      "Epoch 50, Batch 5: 0.589041113853\n",
      "\n",
      "Training Loss: 0.831958413124\n",
      "Validation Loss: 0.870883226395\n",
      "Accuracy (validation): 0.602739751339\n",
      "Epoch 50, Batch 6: 0.602739751339\n",
      "\n",
      "Training Loss: 0.851832389832\n",
      "Validation Loss: 0.871023237705\n",
      "Accuracy (validation): 0.602739751339\n",
      "Epoch 50, Batch 7: 0.602739751339\n",
      "\n",
      "Training Loss: 0.931969285011\n",
      "Validation Loss: 0.870233118534\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 50, Batch 8: 0.575342476368\n",
      "\n",
      "Training Loss: 0.917633235455\n",
      "Validation Loss: 0.867901086807\n",
      "Accuracy (validation): 0.561643838882\n",
      "Epoch 50, Batch 9: 0.561643838882\n",
      "\n",
      "Training Loss: 0.870726764202\n",
      "Validation Loss: 0.865808486938\n",
      "Accuracy (validation): 0.589041113853\n",
      "Epoch 50, Batch 10: 0.589041113853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f5cdbbae9d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d21f25ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training...')\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "accuracy_list = []\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "with tf.Session() as sess:\n",
    "    # It is very important the saver is defined INSIDE the block \"with tf.Session() as sess\"\n",
    "    # otherwise it will be very difficult to load the graph (unless we name all the variables etc)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        for batch_i in range(num_saved_batches - 1):\n",
    "            for batch_inputarrays, batch_labels in zip(batch_list(load_training_data(batch_i), \n",
    "                                                                  size_of_minibatch),\n",
    "                                                       batch_list(load_training_labels(batch_i), \n",
    "                                                                  size_of_minibatch)\n",
    "                                                      ):\n",
    "                sess.run(optimizer, feed_dict={x: batch_inputarrays, y: batch_labels, keep_prob: keep_probability})\n",
    "            (training_cost_value, \n",
    "             validation_cost_value, \n",
    "             accuracy_value) = get_stats(sess, batch_inputarrays, batch_labels, cost, accuracy, \n",
    "                                         printout=True)\n",
    "            \n",
    "            print('Epoch {:>2}, Batch {}: {}'.format(epoch + 1, batch_i, accuracy_value))\n",
    "        \n",
    "        training_losses.append(training_cost_value)\n",
    "        validation_losses.append(validation_cost_value)\n",
    "        accuracy_list.append(accuracy_value)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            # Save the intermediate model\n",
    "            save_path = saver.save(sess, savedmodel_path, global_step=epoch)\n",
    "    \n",
    "    # Save the final model\n",
    "    save_path = saver.save(sess, savedmodel_path, global_step=epoch)\n",
    "        \n",
    "plt.plot(accuracy_list)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.plot(training_losses)\n",
    "plt.plot(validation_losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tune a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.589041\n",
      "\n",
      "Training Loss: 0.844501256943\n",
      "Validation Loss: 0.864791989326\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 51, Batch 0: 0.575342476368\n",
      "\n",
      "Training Loss: 0.819639444351\n",
      "Validation Loss: 0.863854646683\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 51, Batch 1: 0.575342476368\n",
      "\n",
      "Training Loss: 0.8454631567\n",
      "Validation Loss: 0.861890733242\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 51, Batch 2: 0.575342476368\n",
      "\n",
      "Training Loss: 0.930735170841\n",
      "Validation Loss: 0.860491633415\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 51, Batch 3: 0.575342476368\n",
      "\n",
      "Training Loss: 0.856955051422\n",
      "Validation Loss: 0.859154582024\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 51, Batch 4: 0.547945201397\n",
      "\n",
      "Training Loss: 0.831666707993\n",
      "Validation Loss: 0.858529031277\n",
      "Accuracy (validation): 0.547945201397\n",
      "Epoch 51, Batch 5: 0.547945201397\n",
      "\n",
      "Training Loss: 0.831338226795\n",
      "Validation Loss: 0.85829859972\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 51, Batch 6: 0.575342476368\n",
      "\n",
      "Training Loss: 0.845690488815\n",
      "Validation Loss: 0.865056574345\n",
      "Accuracy (validation): 0.589041113853\n",
      "Epoch 51, Batch 7: 0.589041113853\n",
      "\n",
      "Training Loss: 0.911255121231\n",
      "Validation Loss: 0.869135677814\n",
      "Accuracy (validation): 0.589041113853\n",
      "Epoch 51, Batch 8: 0.589041113853\n",
      "\n",
      "Training Loss: 0.928770363331\n",
      "Validation Loss: 0.870498239994\n",
      "Accuracy (validation): 0.575342476368\n",
      "Epoch 51, Batch 9: 0.575342476368\n",
      "\n",
      "Training Loss: 0.82652515173\n",
      "Validation Loss: 0.862945616245\n",
      "Accuracy (validation): 0.602739751339\n",
      "Epoch 51, Batch 10: 0.602739751339\n",
      "\n",
      "Training Loss: 0.815061450005\n",
      "Validation Loss: 0.85637140274\n",
      "Accuracy (validation): 0.602739751339\n",
      "Epoch 52, Batch 0: 0.602739751339\n",
      "\n",
      "Training Loss: 0.799879848957\n",
      "Validation Loss: 0.853124439716\n",
      "Accuracy (validation): 0.602739751339\n",
      "Epoch 52, Batch 1: 0.602739751339\n",
      "\n",
      "Training Loss: 0.816047072411\n",
      "Validation Loss: 0.848048567772\n",
      "Accuracy (validation): 0.602739751339\n",
      "Epoch 52, Batch 2: 0.602739751339\n",
      "\n",
      "Training Loss: 0.929488360882\n",
      "Validation Loss: 0.846260845661\n",
      "Accuracy (validation): 0.602739751339\n",
      "Epoch 52, Batch 3: 0.602739751339\n",
      "\n",
      "Training Loss: 0.832345366478\n",
      "Validation Loss: 0.848198711872\n",
      "Accuracy (validation): 0.602739751339\n",
      "Epoch 52, Batch 4: 0.602739751339\n",
      "\n",
      "Training Loss: 0.816220998764\n",
      "Validation Loss: 0.852705478668\n",
      "Accuracy (validation): 0.602739751339\n",
      "Epoch 52, Batch 5: 0.602739751339\n",
      "\n",
      "Training Loss: 0.821430921555\n",
      "Validation Loss: 0.854896783829\n",
      "Accuracy (validation): 0.589041113853\n",
      "Epoch 52, Batch 6: 0.589041113853\n",
      "\n",
      "Training Loss: 0.833684444427\n",
      "Validation Loss: 0.857715606689\n",
      "Accuracy (validation): 0.589041113853\n",
      "Epoch 52, Batch 7: 0.589041113853\n"
     ]
    }
   ],
   "source": [
    "# Decrease the learning rate for the final part!\n",
    "\n",
    "epochs = 50\n",
    "load_model = savedmodel_path + \"-49\"\n",
    "\n",
    "# read off the epoch from the number in load_model\n",
    "next_epoch = int(load_model[load_model.rfind(\"-\")+1:]) + 1\n",
    "\n",
    "accuracy_list = []\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    saver.restore(sess, load_model)\n",
    "    print(sess.run(accuracy, feed_dict={x: validation_inputarray,\n",
    "                                        y: validation_labels, keep_prob:1.0}))\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(next_epoch, next_epoch + epochs):\n",
    "        for batch_i in range(num_saved_batches - 1):\n",
    "            for batch_inputarrays, batch_labels in zip(batch_list(load_training_data(batch_i), \n",
    "                                                                  size_of_minibatch),\n",
    "                                                       batch_list(load_training_labels(batch_i), \n",
    "                                                                  size_of_minibatch)\n",
    "                                                      ):\n",
    "                sess.run(optimizer, feed_dict={x: batch_inputarrays, y: batch_labels, \n",
    "                                                  keep_prob: keep_probability})\n",
    "            \n",
    "            (training_cost_value, \n",
    "             validation_cost_value, \n",
    "             accuracy_value) = get_stats(sess, batch_inputarrays, batch_labels, cost, accuracy, \n",
    "                                         printout=True)\n",
    "            \n",
    "            print('Epoch {:>2}, Batch {}: {}'.format(epoch + 1, batch_i, accuracy_value))\n",
    "        \n",
    "        training_losses.append(training_cost_value)\n",
    "        validation_losses.append(validation_cost_value)\n",
    "        accuracy_list.append(accuracy_value)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            # Save the intermediate model\n",
    "            ###save_path = saver.save(sess, \"./trained_model\", global_step=epoch)\n",
    "            save_path = saver.save(sess, savedmodel_path, global_step=epoch)\n",
    "            \n",
    "    # Save the final model\n",
    "    ###save_path = saver.save(sess, \"./trained_model\", global_step=epoch)\n",
    "    save_path = saver.save(sess, savedmodel_path, global_step=epoch)\n",
    "    \n",
    "plt.plot(accuracy_list)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.plot(training_losses)\n",
    "plt.plot(validation_losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_model = \"./trained_model-59\"\n",
    "testing_inputarray = np.load(\"./testing_data/testing_images.npy\")\n",
    "testing_labels = np.load(\"./testing_data/testing_labels.npy\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    saver.restore(sess, load_model)\n",
    "    print(\"The model's test-set accuracty is {}%\".format(np.round(sess.run(accuracy, \n",
    "                                                                            feed_dict={x: testing_inputarray,\n",
    "                                        y: testing_labels, keep_prob:1.0})*100, decimals=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7 TensorFlow",
   "language": "python",
   "name": "py27tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
